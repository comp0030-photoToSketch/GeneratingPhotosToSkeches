{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import os.path\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "np.load.__defaults__=(None, True, True, 'ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams():\n",
    "    def __init__(self):\n",
    "        self.data_location = '../Datasets/cat.npz'\n",
    "        self.train_photo_image_path = \"../Datasets/cat/train/\"\n",
    "        self.test_photo_image_path = \"../Datasets/cat/test/\"\n",
    "        self.image_size = 28\n",
    "        self.bottleneck_size = 128\n",
    "        self.enc_hidden_size = 256\n",
    "        self.dec_hidden_size = 512\n",
    "        self.Nz = 128\n",
    "        self.M = 20\n",
    "        self.dropout = 0.9\n",
    "        self.batch_size = 100\n",
    "        self.eta_min = 0.01\n",
    "        self.R = 0.99995\n",
    "        self.KL_min = 0.2\n",
    "        self.wKL = 0.5\n",
    "        self.lr = 0.001\n",
    "        self.lr_decay = 0.9999\n",
    "        self.min_lr = 0.00001\n",
    "        self.grad_clip = 1.\n",
    "        self.temperature = 0.4\n",
    "        self.max_seq_length = 200\n",
    "\n",
    "hp = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_size(data):\n",
    "    \"\"\"larger sequence length in the data set\"\"\"\n",
    "    sizes = [len(seq) for seq in data]\n",
    "    return max(sizes)\n",
    "\n",
    "def purify(strokes):\n",
    "    \"\"\"removes to small or too long sequences + removes large gaps\"\"\"\n",
    "    data = []\n",
    "    for seq in strokes:\n",
    "        if seq.shape[0] <= hp.max_seq_length and seq.shape[0] > 10:\n",
    "            seq = np.minimum(seq, 1000)\n",
    "            seq = np.maximum(seq, -1000)\n",
    "            seq = np.array(seq, dtype=np.float32)\n",
    "            data.append(seq)\n",
    "    return data\n",
    "\n",
    "def calculate_normalizing_scale_factor(strokes):\n",
    "    \"\"\"Calculate the normalizing factor explained in appendix of sketch-rnn.\"\"\"\n",
    "    data = []\n",
    "    for i in range(len(strokes)):\n",
    "        for j in range(len(strokes[i])):\n",
    "            data.append(strokes[i][j, 0])\n",
    "            data.append(strokes[i][j, 1])\n",
    "    data = np.array(data)\n",
    "    return np.std(data)\n",
    "\n",
    "def normalize(strokes):\n",
    "    \"\"\"Normalize entire dataset (delta_x, delta_y) by the scaling factor.\"\"\"\n",
    "    data = []\n",
    "    scale_factor = calculate_normalizing_scale_factor(strokes)\n",
    "    for seq in strokes:\n",
    "        seq[:, 0:2] /= scale_factor\n",
    "        data.append(seq)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(batch_size):\n",
    "    # number of sketches in the dataset\n",
    "    batch_idx = np.random.choice(len(data),batch_size)\n",
    "    batch_sequences = [data[idx] for idx in batch_idx]\n",
    "    strokes = []\n",
    "    lengths = []\n",
    "    indice = 0\n",
    "    \n",
    "    # convert each stroke to stroke-5 representation\n",
    "    for seq in batch_sequences:\n",
    "        len_seq = len(seq[:,0])\n",
    "        new_seq = np.zeros((Nmax,5)) # 66,5\n",
    "        new_seq[:len_seq,:2] = seq[:,:2]\n",
    "        new_seq[:len_seq-1,2] = 1-seq[:-1,2]\n",
    "        new_seq[:len_seq,3] = seq[:,2]\n",
    "        new_seq[(len_seq-1):,4] = 1\n",
    "        new_seq[len_seq-1,2:4] = 0\n",
    "        lengths.append(len(seq[:,0]))\n",
    "        strokes.append(new_seq)\n",
    "        indice += 1\n",
    "\n",
    "    if use_cuda:\n",
    "        batch = Variable(torch.from_numpy(np.stack(strokes,1)).cuda().float())\n",
    "    else:\n",
    "        batch = Variable(torch.from_numpy(np.stack(strokes,1)).float())\n",
    "    return batch, lengths, batch_idx\n",
    "\n",
    "def select_images(indexes):\n",
    "    paths = []\n",
    "    for i in indexes:\n",
    "        paths.append(f\"{hp.train_photo_image_path}{i}.png\")\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(optimizer):\n",
    "    \"\"\"Decay learning rate by a factor of lr_decay\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['lr']>hp.min_lr:\n",
    "            param_group['lr'] *= hp.lr_decay\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(400, 128)  # 6*6 from image dimension\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, image_paths):\n",
    "        all_zs = torch.empty(0, 128)\n",
    "        # Max pooling over a (2, 2) window\n",
    "        for i, data in enumerate(image_paths):\n",
    "            img = mpimg.imread(data)\n",
    "            gray = rgb2gray(img)\n",
    "            x = torch.from_numpy(gray)\n",
    "            # change (28,28) to (1,1,28,28)\n",
    "            x = torch.unsqueeze(x,0)\n",
    "            x = torch.unsqueeze(x,0)\n",
    "            #print(f\"dimension of x {x.shape}\")\n",
    "            x = F.max_pool2d(F.relu(self.conv1(x.float())), (2, 2))\n",
    "            # If the size is a square you can only specify a single number\n",
    "            x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            \n",
    "            #print(x.shape) #1 x 400\n",
    "            x = self.fc1(x)\n",
    "            #print(all_zs.shape)\n",
    "            all_zs = torch.cat([all_zs, x], dim=0)\n",
    "            #all_zs.cat(x)\n",
    "        return all_zs\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # bidirectional lstm:\n",
    "        self.lstm = nn.LSTM(5, hp.enc_hidden_size, \\\n",
    "            dropout=hp.dropout, bidirectional=True)\n",
    "        # create mu and sigma from lstm's last output:\n",
    "        self.fc_mu = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
    "        self.fc_sigma = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
    "        # active dropout:\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, inputs, batch_size, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            # then must init with zeros\n",
    "            if use_cuda:\n",
    "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size).cuda()\n",
    "                cell = torch.zeros(2, batch_size, hp.enc_hidden_size).cuda()\n",
    "            else:\n",
    "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size)\n",
    "                cell = torch.zeros(2, batch_size, hp.enc_hidden_size)\n",
    "            hidden_cell = (hidden, cell)\n",
    "        _, (hidden,cell) = self.lstm(inputs.float(), hidden_cell)\n",
    "        # hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\n",
    "        hidden_forward, hidden_backward = torch.split(hidden,1,0)\n",
    "        hidden_cat = torch.cat([hidden_forward.squeeze(0), hidden_backward.squeeze(0)],1)\n",
    "        # mu and sigma:\n",
    "        mu = self.fc_mu(hidden_cat)\n",
    "        sigma_hat = self.fc_sigma(hidden_cat)\n",
    "        sigma = torch.exp(sigma_hat/2.)\n",
    "        # N ~ N(0,1)\n",
    "        z_size = mu.size()\n",
    "                                   \n",
    "        if use_cuda:\n",
    "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size)).cuda()\n",
    "        else:\n",
    "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size))\n",
    "        z = mu + sigma*N\n",
    "        # mu and sigma_hat are needed for LKL loss\n",
    "        return z, mu, sigma_hat #[100,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # to init hidden and cell from z:\n",
    "        self.fc_hc = nn.Linear(hp.Nz, 2*hp.dec_hidden_size)\n",
    "        # unidirectional lstm:\n",
    "        self.lstm = nn.LSTM(hp.Nz+5, hp.dec_hidden_size, dropout=hp.dropout)\n",
    "        # create proba distribution parameters from hiddens:\n",
    "        self.fc_params = nn.Linear(hp.dec_hidden_size,6*hp.M+3)\n",
    "\n",
    "    def forward(self, inputs, z, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            # then we must init from z\n",
    "            hidden,cell = torch.split(F.tanh(self.fc_hc(z)),hp.dec_hidden_size,1)\n",
    "            hidden_cell = (hidden.unsqueeze(0).contiguous(), cell.unsqueeze(0).contiguous())\n",
    "        outputs,(hidden,cell) = self.lstm(inputs, hidden_cell)\n",
    "        # in training we feed the lstm with the whole input in one shot\n",
    "        # and use all outputs contained in 'outputs', while in generate\n",
    "        # mode we just feed with the last generated sample:\n",
    "        if self.training:\n",
    "            y = self.fc_params(outputs.view(-1, hp.dec_hidden_size))\n",
    "        else:\n",
    "            y = self.fc_params(hidden.view(-1, hp.dec_hidden_size))\n",
    "        # separate pen and mixture params:\n",
    "        params = torch.split(y,6,1)\n",
    "        params_mixture = torch.stack(params[:-1]) # trajectory\n",
    "        params_pen = params[-1] # pen up/down\n",
    "        # identify mixture params:\n",
    "        pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy = torch.split(params_mixture,1,2)\n",
    "        # preprocess params::\n",
    "        if self.training:\n",
    "            len_out = Nmax+1\n",
    "        else:\n",
    "            len_out = 1\n",
    "                                   \n",
    "        pi = F.softmax(pi.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_x = torch.exp(sigma_x.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_y = torch.exp(sigma_y.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        rho_xy = torch.tanh(rho_xy.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        mu_x = mu_x.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        mu_y = mu_y.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        q = F.softmax(params_pen).view(len_out,-1,3)\n",
    "        return pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy,q,hidden,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        if use_cuda:\n",
    "            self.encoderRNN = EncoderRNN().cuda()\n",
    "            saved_encoder = torch.load('../Models/sketchRNN_encoder_0.320616_7000.pt')\n",
    "            self.encoderRNN.load_state_dict(saved_encoder)\n",
    "            self.encoder = ImageEncoder().cuda()\n",
    "            self.decoder = DecoderRNN().cuda()\n",
    "        else:\n",
    "            self.encoderRNN = EncoderRNN()\n",
    "            saved_encoder = torch.load('../Models/sketchRNN_encoder_0.320616_7000.pt')\n",
    "            self.encoderRNN.load_state_dict(saved_encoder)\n",
    "            self.encoder = ImageEncoder()\n",
    "            self.decoder = DecoderRNN()\n",
    "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), hp.lr)\n",
    "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), hp.lr)\n",
    "        self.eta_step = hp.eta_min\n",
    "\n",
    "    def make_target(self, batch, lengths):\n",
    "        if use_cuda:\n",
    "            eos = torch.stack([torch.Tensor([0,0,0,0,1])]*batch.size()[1]).cuda().unsqueeze(0)\n",
    "        else:\n",
    "            eos = torch.stack([torch.Tensor([0,0,0,0,1])]*batch.size()[1]).unsqueeze(0)\n",
    "        batch = torch.cat([batch, eos], 0)\n",
    "        mask = torch.zeros(Nmax+1, batch.size()[1])\n",
    "        for indice,length in enumerate(lengths):\n",
    "            mask[:length,indice] = 1\n",
    "        if use_cuda:\n",
    "            mask = mask.cuda()\n",
    "        dx = torch.stack([batch.data[:,:,0]]*hp.M,2)\n",
    "        dy = torch.stack([batch.data[:,:,1]]*hp.M,2)\n",
    "        p1 = batch.data[:,:,2]\n",
    "        p2 = batch.data[:,:,3]\n",
    "        p3 = batch.data[:,:,4]\n",
    "        p = torch.stack([p1,p2,p3],2)\n",
    "        return mask,dx,dy,p\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        \n",
    "        # EncoderRNN(a batch of sequences) -> a single z\n",
    "        # ImageEncoder(a batch of images) -> single z\n",
    "                # EncoderRNN(same corresponsing batch of images) -> single z\n",
    "        # single image x single sequence\n",
    "        \n",
    "        batch, lengths, indexes = make_batch(hp.batch_size)\n",
    "        \n",
    "        img_paths = select_images(indexes)\n",
    "        \n",
    "        # RNN encoder:\n",
    "        target_z, self.mu, self.sigma = self.encoderRNN(batch, hp.batch_size)\n",
    "\n",
    "        # Image encoder:\n",
    "        predicted_z = self.encoder(img_paths)\n",
    "        \n",
    "        # create start of sequence:\n",
    "        if use_cuda:\n",
    "            sos = torch.stack([torch.Tensor([0,0,1,0,0])]*hp.batch_size).cuda().unsqueeze(0)\n",
    "        else:\n",
    "            sos = torch.stack([torch.Tensor([0,0,1,0,0])]*hp.batch_size).unsqueeze(0)\n",
    "        # had sos at the begining of the batch:\n",
    "        batch_init = torch.cat([sos, batch],0)\n",
    "        # expend z to be ready to concatenate with inputs:\n",
    "        z_stack = torch.stack([predicted_z]*(Nmax+1))\n",
    "        # inputs is concatenation of z and batch_inputs\n",
    "        inputs = torch.cat([batch_init, z_stack],2)\n",
    "        \n",
    "        # decode:\n",
    "        self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "            self.rho_xy, self.q, _, _ = self.decoder(inputs, predicted_z)\n",
    "        # prepare targets:\n",
    "        mask,dx,dy,p = self.make_target(batch, lengths)\n",
    "        \n",
    "        # prepare optimizers:\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "        \n",
    "        # update eta for LKL:\n",
    "        self.eta_step = 1-(1-hp.eta_min)*hp.R\n",
    "        \n",
    "        # compute losses:\n",
    "        LKL = self.kullback_leibler_loss()\n",
    "        LR = self.reconstruction_loss(mask,dx,dy,p,epoch)\n",
    "        EL = self.encoder_loss(predicted_z, target_z)\n",
    "        \n",
    "        loss = LR + LKL + (EL * 2) \n",
    "        \n",
    "        # gradient step\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient cliping\n",
    "        nn.utils.clip_grad_norm(self.encoder.parameters(), hp.grad_clip)\n",
    "        nn.utils.clip_grad_norm(self.decoder.parameters(), hp.grad_clip)\n",
    "        \n",
    "        # optim step\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "        \n",
    "        # some print and save:\n",
    "        if epoch%1==0:\n",
    "            print(f\"The number of epochs is: {epoch} and loss is {loss}\")\n",
    "            self.encoder_optimizer = lr_decay(self.encoder_optimizer)\n",
    "            self.decoder_optimizer = lr_decay(self.decoder_optimizer)\n",
    "        if epoch%100==0:\n",
    "            self.save(epoch)\n",
    "            #self.conditional_generation(epoch)\n",
    "\n",
    "    def bivariate_normal_pdf(self, dx, dy):\n",
    "        z_x = ((dx-self.mu_x)/self.sigma_x)**2\n",
    "        z_y = ((dy-self.mu_y)/self.sigma_y)**2\n",
    "        z_xy = (dx-self.mu_x)*(dy-self.mu_y)/(self.sigma_x*self.sigma_y)\n",
    "        z = z_x + z_y -2*self.rho_xy*z_xy\n",
    "        exp = torch.exp(-z/(2*(1-self.rho_xy**2)))\n",
    "        norm = 2*np.pi*self.sigma_x*self.sigma_y*torch.sqrt(1-self.rho_xy**2)\n",
    "        return exp/norm\n",
    "    \n",
    "    def encoder_loss(self, pred_z, target_z):\n",
    "        criterion = nn.MSELoss()\n",
    "        return criterion(pred_z, target_z)\n",
    "\n",
    "    def reconstruction_loss(self, mask, dx, dy, p, epoch):\n",
    "        pdf = self.bivariate_normal_pdf(dx, dy)\n",
    "        LS = -torch.sum(mask*torch.log(1e-5+torch.sum(self.pi * pdf, 2)))\\\n",
    "            /float(Nmax*hp.batch_size)\n",
    "        LP = -torch.sum(p*torch.log(self.q))/float(Nmax*hp.batch_size)\n",
    "        return LS+LP\n",
    "\n",
    "    def kullback_leibler_loss(self):\n",
    "        LKL = -0.5*torch.sum(1+self.sigma-self.mu**2-torch.exp(self.sigma))\\\n",
    "            /float(hp.Nz*hp.batch_size)\n",
    "        if use_cuda:\n",
    "            KL_min = Variable(torch.Tensor([hp.KL_min]).cuda()).detach()\n",
    "        else:\n",
    "            KL_min = Variable(torch.Tensor([hp.KL_min])).detach()\n",
    "        return hp.wKL*self.eta_step * torch.max(LKL,KL_min)\n",
    "\n",
    "    def save(self, epoch):\n",
    "        random_number = np.random.rand()\n",
    "        enc_model_name = 'sketchRNN_encoder_%3f_%d.pt' % (random_number, epoch)\n",
    "        enc_path = F\"../Models_Complete/{enc_model_name}\"\n",
    "        torch.save(self.encoder.state_dict(), enc_path)\n",
    "        dec_model_name = 'sketchRNN_decoder_%3f_%d.pt' % (random_number, epoch)\n",
    "        dec_path = F\"../Models_Complete/{dec_model_name}\"\n",
    "        torch.save(self.decoder.state_dict(), dec_path)\n",
    "\n",
    "    def load(self, encoder_name, decoder_name):\n",
    "        saved_encoder = torch.load(encoder_name)\n",
    "        saved_decoder = torch.load(decoder_name)\n",
    "        self.encoder.load_state_dict(saved_encoder)\n",
    "        self.decoder.load_state_dict(saved_decoder)\n",
    "\n",
    "    def conditional_generation(self, z):\n",
    "        #batch,lengths = make_batch(1)\n",
    "        # should remove dropouts:\n",
    "        self.encoder.train(False)\n",
    "        self.decoder.train(False)\n",
    "        # encode:\n",
    "        #z, _, _ = self.encoder(batch, 1)\n",
    "        if use_cuda:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1).cuda())\n",
    "        else:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1))\n",
    "        s = sos\n",
    "        seq_x = []\n",
    "        seq_y = []\n",
    "        seq_z = []\n",
    "        hidden_cell = None\n",
    "        for i in range(Nmax):\n",
    "            input = torch.cat([s,z.unsqueeze(0)],2)\n",
    "            # decode:\n",
    "            self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "                self.rho_xy, self.q, hidden, cell = \\\n",
    "                    self.decoder(input, z, hidden_cell)\n",
    "            hidden_cell = (hidden, cell)\n",
    "            # sample from parameters:\n",
    "            s, dx, dy, pen_down, eos = self.sample_next_state()\n",
    "            #------\n",
    "            seq_x.append(dx)\n",
    "            seq_y.append(dy)\n",
    "            seq_z.append(pen_down)\n",
    "            if eos:\n",
    "                print(i)\n",
    "                break\n",
    "        # visualize result:\n",
    "        x_sample = np.cumsum(seq_x, 0)\n",
    "        y_sample = np.cumsum(seq_y, 0)\n",
    "        z_sample = np.array(seq_z)\n",
    "        sequence = np.stack([x_sample,y_sample,z_sample]).T\n",
    "        make_image(sequence, epoch)\n",
    "        \n",
    "    def getStrokesToPlot(self, z):\n",
    "        self.encoder.train(False)\n",
    "        self.decoder.train(False)\n",
    "        if use_cuda:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1).cuda())\n",
    "        else:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1))\n",
    "        s = sos\n",
    "        seq_x = []\n",
    "        seq_y = []\n",
    "        seq_z = []\n",
    "        hidden_cell = None\n",
    "        for i in range(Nmax):\n",
    "            input = torch.cat([s,z.unsqueeze(0)],2)\n",
    "            # decode:\n",
    "            self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "                self.rho_xy, self.q, hidden, cell = \\\n",
    "                    self.decoder(input, z, hidden_cell)\n",
    "            hidden_cell = (hidden, cell)\n",
    "            # sample from parameters:\n",
    "            s, dx, dy, pen_down, eos = self.sample_next_state()\n",
    "            #------\n",
    "            seq_x.append(dx)\n",
    "            seq_y.append(dy)\n",
    "            seq_z.append(pen_down)\n",
    "            if eos:\n",
    "                print(i)\n",
    "                break\n",
    "        # visualize result:\n",
    "        x_sample = np.cumsum(seq_x, 0)\n",
    "        y_sample = np.cumsum(seq_y, 0)\n",
    "        z_sample = np.array(seq_z)\n",
    "        sequence = np.stack([x_sample,y_sample,z_sample]).T\n",
    "        return sequence\n",
    "\n",
    "    def sample_next_state(self):\n",
    "        def adjust_temp(pi_pdf):\n",
    "            pi_pdf = np.log(pi_pdf)/hp.temperature\n",
    "            pi_pdf -= pi_pdf.max()\n",
    "            pi_pdf = np.exp(pi_pdf)\n",
    "            pi_pdf /= pi_pdf.sum()\n",
    "            return pi_pdf\n",
    "\n",
    "        # get mixture indice:\n",
    "        pi = self.pi.data[0,0,:].cpu().numpy()\n",
    "        pi = adjust_temp(pi)\n",
    "        pi_idx = np.random.choice(hp.M, p=pi)\n",
    "        # get pen state:\n",
    "        q = self.q.data[0,0,:].cpu().numpy()\n",
    "        q = adjust_temp(q)\n",
    "        q_idx = np.random.choice(3, p=q)\n",
    "        # get mixture params:\n",
    "        mu_x = self.mu_x.data[0,0,pi_idx]\n",
    "        mu_y = self.mu_y.data[0,0,pi_idx]\n",
    "        sigma_x = self.sigma_x.data[0,0,pi_idx]\n",
    "        sigma_y = self.sigma_y.data[0,0,pi_idx]\n",
    "        rho_xy = self.rho_xy.data[0,0,pi_idx]\n",
    "        x,y = sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy,greedy=False)\n",
    "        next_state = torch.zeros(5)\n",
    "        next_state[0] = x\n",
    "        next_state[1] = y\n",
    "        next_state[q_idx+2] = 1\n",
    "        if use_cuda:\n",
    "            return Variable(next_state.cuda()).view(1,1,-1),x,y,q_idx==1,q_idx==2\n",
    "        else:\n",
    "            return Variable(next_state).view(1,1,-1),x,y,q_idx==1,q_idx==2\n",
    "\n",
    "def sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy, greedy=False):\n",
    "    # inputs must be floats\n",
    "    if greedy:\n",
    "        return mu_x,mu_y\n",
    "    mean = [mu_x, mu_y]\n",
    "    sigma_x *= np.sqrt(hp.temperature)\n",
    "    sigma_y *= np.sqrt(hp.temperature)\n",
    "    cov = [[sigma_x * sigma_x, rho_xy * sigma_x * sigma_y],\\\n",
    "        [rho_xy * sigma_x * sigma_y, sigma_y * sigma_y]]\n",
    "    x = np.random.multivariate_normal(mean, cov, 1)\n",
    "    return x[0][0], x[0][1]\n",
    "\n",
    "def make_image(sequence):\n",
    "    \"\"\"plot drawing with separated strokes\"\"\"\n",
    "    strokes = np.split(sequence, np.where(sequence[:,2]>0)[0]+1)\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1,1,1)\n",
    "    for s in strokes:\n",
    "        plt.plot(s[:,0],-s[:,1])\n",
    "    #print(\"Outputting sketch\")\n",
    "    #name = str(epoch)+name+'.jpg'\n",
    "    #plt.savefig(F\"./outputs_complete/{name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling data\n",
    "\n",
    "dataset = np.load(hp.data_location, encoding='latin1')\n",
    "data = dataset['train']\n",
    "data = purify(data)\n",
    "data = normalize(data)\n",
    "Nmax = max_size(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 0 and loss is tensor([2.6487], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1 and loss is tensor([2.6932], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 2 and loss is tensor([2.5609], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 3 and loss is tensor([2.3505], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 4 and loss is tensor([2.4040], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 5 and loss is tensor([2.5152], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 6 and loss is tensor([2.4172], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 7 and loss is tensor([2.2152], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 8 and loss is tensor([2.0969], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 9 and loss is tensor([2.0431], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 10 and loss is tensor([2.0455], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 11 and loss is tensor([1.8541], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 12 and loss is tensor([2.0650], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 13 and loss is tensor([1.8747], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 14 and loss is tensor([1.6870], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 15 and loss is tensor([2.6567], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 16 and loss is tensor([2.4402], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 17 and loss is tensor([1.7298], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 18 and loss is tensor([1.7239], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 19 and loss is tensor([1.7289], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 20 and loss is tensor([1.6857], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 21 and loss is tensor([1.5767], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 22 and loss is tensor([1.6374], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 23 and loss is tensor([1.7533], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 24 and loss is tensor([2.1375], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 25 and loss is tensor([1.7515], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 26 and loss is tensor([1.5590], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 27 and loss is tensor([1.5216], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 28 and loss is tensor([1.5430], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 29 and loss is tensor([1.6611], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 30 and loss is tensor([1.5901], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 31 and loss is tensor([1.6952], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 32 and loss is tensor([1.4689], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 33 and loss is tensor([1.5578], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 34 and loss is tensor([1.4808], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 35 and loss is tensor([1.5312], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 36 and loss is tensor([1.5615], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 37 and loss is tensor([1.5652], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 38 and loss is tensor([1.5463], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 39 and loss is tensor([1.5173], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 40 and loss is tensor([1.4388], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 41 and loss is tensor([1.5349], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 42 and loss is tensor([1.4717], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 43 and loss is tensor([1.4471], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 44 and loss is tensor([1.4440], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 45 and loss is tensor([1.3679], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 46 and loss is tensor([1.4125], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 47 and loss is tensor([1.4609], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 48 and loss is tensor([1.4072], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 49 and loss is tensor([1.4855], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 50 and loss is tensor([1.4305], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 51 and loss is tensor([1.4449], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 52 and loss is tensor([1.3159], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 53 and loss is tensor([1.3240], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 54 and loss is tensor([1.3863], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 55 and loss is tensor([1.3805], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 56 and loss is tensor([1.3888], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 57 and loss is tensor([1.3533], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 58 and loss is tensor([1.3217], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 59 and loss is tensor([1.4137], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 60 and loss is tensor([1.4514], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 61 and loss is tensor([1.5877], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 62 and loss is tensor([1.3202], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 63 and loss is tensor([1.3970], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 64 and loss is tensor([1.4448], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 65 and loss is tensor([1.3706], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 66 and loss is tensor([1.3351], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 67 and loss is tensor([1.3708], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 68 and loss is tensor([1.3611], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 69 and loss is tensor([1.2922], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 70 and loss is tensor([1.3367], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 71 and loss is tensor([1.3060], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 72 and loss is tensor([1.2866], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 73 and loss is tensor([1.3100], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 74 and loss is tensor([1.2521], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 75 and loss is tensor([1.3677], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 76 and loss is tensor([1.3871], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 77 and loss is tensor([1.3026], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 78 and loss is tensor([1.3229], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 79 and loss is tensor([1.1984], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 80 and loss is tensor([1.3564], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 81 and loss is tensor([1.2448], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 82 and loss is tensor([1.3085], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 83 and loss is tensor([1.2719], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 84 and loss is tensor([1.3675], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 85 and loss is tensor([1.2742], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 86 and loss is tensor([1.2129], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 87 and loss is tensor([1.2494], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 88 and loss is tensor([1.2670], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 89 and loss is tensor([1.1829], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 90 and loss is tensor([1.2262], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 91 and loss is tensor([1.2401], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 92 and loss is tensor([1.1759], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 93 and loss is tensor([1.1539], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 94 and loss is tensor([1.1675], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 95 and loss is tensor([1.1727], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 96 and loss is tensor([1.2204], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 97 and loss is tensor([1.1931], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 98 and loss is tensor([1.1663], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 99 and loss is tensor([1.2691], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 100 and loss is tensor([1.1476], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 101 and loss is tensor([1.1634], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 102 and loss is tensor([1.1375], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 103 and loss is tensor([1.1328], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 104 and loss is tensor([1.1172], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 105 and loss is tensor([1.1469], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 106 and loss is tensor([1.1760], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 107 and loss is tensor([1.0656], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 108 and loss is tensor([1.1751], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 109 and loss is tensor([1.1024], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 110 and loss is tensor([1.1259], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 111 and loss is tensor([1.0973], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 112 and loss is tensor([1.1137], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 113 and loss is tensor([1.1205], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 114 and loss is tensor([1.0297], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 115 and loss is tensor([1.1278], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 116 and loss is tensor([1.1539], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 117 and loss is tensor([1.0424], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 118 and loss is tensor([1.0417], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 119 and loss is tensor([1.0872], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 120 and loss is tensor([0.9745], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 121 and loss is tensor([1.0794], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 122 and loss is tensor([1.0881], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 123 and loss is tensor([1.0424], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 124 and loss is tensor([1.0620], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 125 and loss is tensor([1.0776], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 126 and loss is tensor([1.0465], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 127 and loss is tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 128 and loss is tensor([1.0775], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 129 and loss is tensor([0.9664], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 130 and loss is tensor([0.9638], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 131 and loss is tensor([1.0484], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 132 and loss is tensor([1.0210], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 133 and loss is tensor([0.9781], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 134 and loss is tensor([0.9464], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 135 and loss is tensor([1.0229], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 136 and loss is tensor([1.0111], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 137 and loss is tensor([0.9840], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 138 and loss is tensor([1.0027], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 139 and loss is tensor([0.9971], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 140 and loss is tensor([0.9969], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 141 and loss is tensor([0.9430], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 142 and loss is tensor([0.9920], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 143 and loss is tensor([1.0091], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 144 and loss is tensor([0.9009], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 145 and loss is tensor([1.0655], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 146 and loss is tensor([0.9226], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 147 and loss is tensor([0.9773], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 148 and loss is tensor([0.9430], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 149 and loss is tensor([0.9149], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 150 and loss is tensor([0.9426], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 151 and loss is tensor([1.0259], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 152 and loss is tensor([0.9526], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 153 and loss is tensor([0.9785], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 154 and loss is tensor([0.9280], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 155 and loss is tensor([0.9518], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 156 and loss is tensor([0.8799], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 157 and loss is tensor([0.9118], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 158 and loss is tensor([1.0326], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 159 and loss is tensor([0.9593], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 160 and loss is tensor([0.9381], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 161 and loss is tensor([0.9883], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 162 and loss is tensor([0.9081], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 163 and loss is tensor([0.9648], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 164 and loss is tensor([0.9532], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 165 and loss is tensor([0.9271], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 166 and loss is tensor([0.9296], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 167 and loss is tensor([0.8366], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 168 and loss is tensor([0.8486], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 169 and loss is tensor([0.9414], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 170 and loss is tensor([0.9594], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 171 and loss is tensor([0.9270], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 172 and loss is tensor([0.8446], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 173 and loss is tensor([0.8471], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 174 and loss is tensor([0.8537], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 175 and loss is tensor([0.9282], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 176 and loss is tensor([0.9267], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 177 and loss is tensor([0.9172], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 178 and loss is tensor([0.8832], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 179 and loss is tensor([0.9221], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 180 and loss is tensor([0.9775], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 181 and loss is tensor([0.9420], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 182 and loss is tensor([0.8354], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 183 and loss is tensor([0.8633], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 184 and loss is tensor([0.9332], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 185 and loss is tensor([0.8586], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 186 and loss is tensor([0.8852], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 187 and loss is tensor([0.8712], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 188 and loss is tensor([0.8334], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 189 and loss is tensor([0.8178], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 190 and loss is tensor([0.8918], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 191 and loss is tensor([0.9201], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 192 and loss is tensor([0.8399], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 193 and loss is tensor([0.8680], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 194 and loss is tensor([0.8612], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 195 and loss is tensor([0.8895], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 196 and loss is tensor([0.8572], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 197 and loss is tensor([0.7925], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 198 and loss is tensor([0.8950], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 199 and loss is tensor([0.8361], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 200 and loss is tensor([0.9197], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 201 and loss is tensor([0.8265], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 202 and loss is tensor([0.8747], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 203 and loss is tensor([0.8851], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 204 and loss is tensor([0.8611], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 205 and loss is tensor([0.8777], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 206 and loss is tensor([0.8819], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 207 and loss is tensor([0.8036], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 208 and loss is tensor([0.8614], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 209 and loss is tensor([0.8049], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 210 and loss is tensor([0.9029], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 211 and loss is tensor([0.7928], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 212 and loss is tensor([0.8495], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 213 and loss is tensor([0.8427], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 214 and loss is tensor([0.8267], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 215 and loss is tensor([0.8064], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 216 and loss is tensor([0.8390], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 217 and loss is tensor([0.7768], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 218 and loss is tensor([0.8595], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 219 and loss is tensor([0.8153], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 220 and loss is tensor([0.8673], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 221 and loss is tensor([0.8033], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 222 and loss is tensor([0.8463], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 223 and loss is tensor([0.8347], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 224 and loss is tensor([0.8053], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 225 and loss is tensor([0.7798], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 226 and loss is tensor([0.8283], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 227 and loss is tensor([0.8273], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 228 and loss is tensor([0.8467], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 229 and loss is tensor([0.7858], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 230 and loss is tensor([0.7571], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 231 and loss is tensor([0.8178], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 232 and loss is tensor([0.8063], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 233 and loss is tensor([0.8472], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 234 and loss is tensor([0.7188], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 235 and loss is tensor([0.8276], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 236 and loss is tensor([0.7552], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 237 and loss is tensor([0.7901], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 238 and loss is tensor([0.7722], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 239 and loss is tensor([0.8040], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 240 and loss is tensor([0.7857], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 241 and loss is tensor([0.7402], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 242 and loss is tensor([0.7436], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 243 and loss is tensor([0.7694], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 244 and loss is tensor([0.7623], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 245 and loss is tensor([0.8607], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 246 and loss is tensor([0.8211], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 247 and loss is tensor([0.8300], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 248 and loss is tensor([0.7414], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 249 and loss is tensor([0.8395], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 250 and loss is tensor([0.7680], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 251 and loss is tensor([0.7188], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 252 and loss is tensor([0.8272], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 253 and loss is tensor([0.7712], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 254 and loss is tensor([0.7721], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 255 and loss is tensor([0.7520], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 256 and loss is tensor([0.8074], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 257 and loss is tensor([0.7287], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 258 and loss is tensor([0.7119], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 259 and loss is tensor([0.8338], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 260 and loss is tensor([0.7457], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 261 and loss is tensor([0.7609], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 262 and loss is tensor([0.7395], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 263 and loss is tensor([0.7626], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 264 and loss is tensor([0.7841], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 265 and loss is tensor([0.7623], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 266 and loss is tensor([0.7768], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 267 and loss is tensor([0.7897], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 268 and loss is tensor([0.7765], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 269 and loss is tensor([0.8059], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 270 and loss is tensor([0.8204], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 271 and loss is tensor([0.7688], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 272 and loss is tensor([0.7677], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 273 and loss is tensor([0.7329], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 274 and loss is tensor([0.8569], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 275 and loss is tensor([0.7558], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 276 and loss is tensor([0.7665], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 277 and loss is tensor([0.7885], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 278 and loss is tensor([0.7087], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 279 and loss is tensor([0.7375], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 280 and loss is tensor([0.7437], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 281 and loss is tensor([0.7305], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 282 and loss is tensor([0.7906], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 283 and loss is tensor([0.7278], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 284 and loss is tensor([0.7145], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 285 and loss is tensor([0.7290], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 286 and loss is tensor([0.7542], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 287 and loss is tensor([0.7464], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 288 and loss is tensor([0.8340], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 289 and loss is tensor([0.7883], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 290 and loss is tensor([0.7061], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 291 and loss is tensor([0.6995], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 292 and loss is tensor([0.7586], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 293 and loss is tensor([0.7357], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 294 and loss is tensor([0.7102], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 295 and loss is tensor([0.7803], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 296 and loss is tensor([0.7245], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 297 and loss is tensor([0.6695], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 298 and loss is tensor([0.7308], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 299 and loss is tensor([0.6981], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 300 and loss is tensor([0.6995], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 301 and loss is tensor([0.7434], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 302 and loss is tensor([0.7066], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 303 and loss is tensor([0.7285], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 304 and loss is tensor([0.7425], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 305 and loss is tensor([0.7762], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 306 and loss is tensor([0.7279], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 307 and loss is tensor([0.7221], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 308 and loss is tensor([0.7111], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 309 and loss is tensor([0.7682], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 310 and loss is tensor([0.7070], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 311 and loss is tensor([0.7776], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 312 and loss is tensor([0.7119], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 313 and loss is tensor([0.7777], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 314 and loss is tensor([0.6605], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 315 and loss is tensor([0.8216], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 316 and loss is tensor([0.7001], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 317 and loss is tensor([0.7568], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 318 and loss is tensor([0.7356], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 319 and loss is tensor([0.6974], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 320 and loss is tensor([0.6522], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 321 and loss is tensor([0.7502], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 322 and loss is tensor([0.6589], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 323 and loss is tensor([0.7255], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 324 and loss is tensor([0.6995], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 325 and loss is tensor([0.7145], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 326 and loss is tensor([0.7423], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 327 and loss is tensor([0.6819], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 328 and loss is tensor([0.6541], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 329 and loss is tensor([0.6776], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 330 and loss is tensor([0.7430], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 331 and loss is tensor([0.7220], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 332 and loss is tensor([0.7717], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 333 and loss is tensor([0.6923], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 334 and loss is tensor([0.7688], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 335 and loss is tensor([0.6636], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 336 and loss is tensor([0.7663], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 337 and loss is tensor([0.6739], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 338 and loss is tensor([0.6834], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 339 and loss is tensor([0.7175], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 340 and loss is tensor([0.7016], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 341 and loss is tensor([0.7176], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 342 and loss is tensor([0.7051], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 343 and loss is tensor([0.7297], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 344 and loss is tensor([0.6844], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 345 and loss is tensor([0.7612], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 346 and loss is tensor([0.6723], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 347 and loss is tensor([0.7682], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 348 and loss is tensor([0.7323], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 349 and loss is tensor([0.7479], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 350 and loss is tensor([0.7133], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 351 and loss is tensor([0.6980], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 352 and loss is tensor([0.6723], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 353 and loss is tensor([0.6933], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 354 and loss is tensor([0.6950], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 355 and loss is tensor([0.6685], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 356 and loss is tensor([0.7362], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 357 and loss is tensor([0.7424], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 358 and loss is tensor([0.7457], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 359 and loss is tensor([0.7128], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 360 and loss is tensor([0.6947], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 361 and loss is tensor([0.7071], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 362 and loss is tensor([0.6977], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 363 and loss is tensor([0.7130], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 364 and loss is tensor([0.6776], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 365 and loss is tensor([0.6662], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 366 and loss is tensor([0.7138], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 367 and loss is tensor([0.6878], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 368 and loss is tensor([0.6651], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 369 and loss is tensor([0.6500], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 370 and loss is tensor([0.6998], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 371 and loss is tensor([0.6350], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 372 and loss is tensor([0.6986], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 373 and loss is tensor([0.7137], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 374 and loss is tensor([0.7024], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 375 and loss is tensor([0.6664], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 376 and loss is tensor([0.7210], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 377 and loss is tensor([0.7166], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 378 and loss is tensor([0.6775], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 379 and loss is tensor([0.6897], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 380 and loss is tensor([0.6986], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 381 and loss is tensor([0.6345], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 382 and loss is tensor([0.6979], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 383 and loss is tensor([0.7208], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 384 and loss is tensor([0.6927], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 385 and loss is tensor([0.6226], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 386 and loss is tensor([0.7349], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 387 and loss is tensor([0.7074], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 388 and loss is tensor([0.7389], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 389 and loss is tensor([0.7190], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 390 and loss is tensor([0.7216], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 391 and loss is tensor([0.6059], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 392 and loss is tensor([0.6384], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 393 and loss is tensor([0.7945], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 394 and loss is tensor([0.7112], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 395 and loss is tensor([0.6811], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 396 and loss is tensor([0.7190], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 397 and loss is tensor([0.6323], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 398 and loss is tensor([0.6904], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 399 and loss is tensor([0.6781], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 400 and loss is tensor([0.7080], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 401 and loss is tensor([0.7127], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 402 and loss is tensor([0.6444], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 403 and loss is tensor([0.6885], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 404 and loss is tensor([0.7249], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 405 and loss is tensor([0.7451], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 406 and loss is tensor([0.7428], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 407 and loss is tensor([0.6328], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 408 and loss is tensor([0.6975], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 409 and loss is tensor([0.6311], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 410 and loss is tensor([0.6944], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 411 and loss is tensor([0.7459], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 412 and loss is tensor([0.6856], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 413 and loss is tensor([0.6770], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 414 and loss is tensor([0.7259], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 415 and loss is tensor([0.6752], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 416 and loss is tensor([0.6386], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 417 and loss is tensor([0.6554], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 418 and loss is tensor([0.7344], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 419 and loss is tensor([0.6744], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 420 and loss is tensor([0.6817], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 421 and loss is tensor([0.6842], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 422 and loss is tensor([0.6776], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 423 and loss is tensor([0.6858], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 424 and loss is tensor([0.6443], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 425 and loss is tensor([0.6284], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 426 and loss is tensor([0.6638], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 427 and loss is tensor([0.6224], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 428 and loss is tensor([0.6502], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 429 and loss is tensor([0.6376], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 430 and loss is tensor([0.6438], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 431 and loss is tensor([0.6572], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 432 and loss is tensor([0.6781], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 433 and loss is tensor([0.6636], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 434 and loss is tensor([0.6271], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 435 and loss is tensor([0.6875], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 436 and loss is tensor([0.6288], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 437 and loss is tensor([0.7132], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 438 and loss is tensor([0.6702], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 439 and loss is tensor([0.6232], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 440 and loss is tensor([0.6548], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 441 and loss is tensor([0.6963], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 442 and loss is tensor([0.7255], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 443 and loss is tensor([0.6772], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 444 and loss is tensor([0.7132], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 445 and loss is tensor([0.6853], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 446 and loss is tensor([0.6661], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 447 and loss is tensor([0.6232], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 448 and loss is tensor([0.6821], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 449 and loss is tensor([0.6586], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 450 and loss is tensor([0.6484], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 451 and loss is tensor([0.6717], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 452 and loss is tensor([0.7110], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 453 and loss is tensor([0.6495], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 454 and loss is tensor([0.6383], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 455 and loss is tensor([0.6697], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 456 and loss is tensor([0.5675], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 457 and loss is tensor([0.6510], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 458 and loss is tensor([0.6280], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 459 and loss is tensor([0.6745], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 460 and loss is tensor([0.6280], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 461 and loss is tensor([0.6009], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 462 and loss is tensor([0.6752], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 463 and loss is tensor([0.6401], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 464 and loss is tensor([0.5865], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 465 and loss is tensor([0.6106], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 466 and loss is tensor([0.6378], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 467 and loss is tensor([0.6923], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 468 and loss is tensor([0.6846], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 469 and loss is tensor([0.6548], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 470 and loss is tensor([0.5905], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 471 and loss is tensor([0.6424], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 472 and loss is tensor([0.6622], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 473 and loss is tensor([0.6035], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 474 and loss is tensor([0.6328], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 475 and loss is tensor([0.6695], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 476 and loss is tensor([0.6216], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 477 and loss is tensor([0.6205], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 478 and loss is tensor([0.6419], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 479 and loss is tensor([0.6921], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 480 and loss is tensor([0.5837], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 481 and loss is tensor([0.6853], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 482 and loss is tensor([0.6601], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 483 and loss is tensor([0.6610], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 484 and loss is tensor([0.6181], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 485 and loss is tensor([0.5861], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 486 and loss is tensor([0.5682], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 487 and loss is tensor([0.6174], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 488 and loss is tensor([0.6033], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 489 and loss is tensor([0.6563], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 490 and loss is tensor([0.5987], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 491 and loss is tensor([0.6203], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 492 and loss is tensor([0.6166], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 493 and loss is tensor([0.6486], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 494 and loss is tensor([0.6409], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 495 and loss is tensor([0.5921], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 496 and loss is tensor([0.6865], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 497 and loss is tensor([0.6025], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 498 and loss is tensor([0.6543], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 499 and loss is tensor([0.6360], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 500 and loss is tensor([0.5986], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 501 and loss is tensor([0.5891], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 502 and loss is tensor([0.6545], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 503 and loss is tensor([0.6130], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 504 and loss is tensor([0.6922], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 505 and loss is tensor([0.6027], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 506 and loss is tensor([0.6005], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 507 and loss is tensor([0.6269], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 508 and loss is tensor([0.6432], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 509 and loss is tensor([0.6089], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 510 and loss is tensor([0.6224], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 511 and loss is tensor([0.5845], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 512 and loss is tensor([0.5780], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 513 and loss is tensor([0.6405], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 514 and loss is tensor([0.5968], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 515 and loss is tensor([0.6776], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 516 and loss is tensor([0.5584], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 517 and loss is tensor([0.6337], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 518 and loss is tensor([0.6260], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 519 and loss is tensor([0.6570], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 520 and loss is tensor([0.6190], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 521 and loss is tensor([0.6414], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 522 and loss is tensor([0.6169], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 523 and loss is tensor([0.6180], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 524 and loss is tensor([0.5836], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 525 and loss is tensor([0.5706], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 526 and loss is tensor([0.6391], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 527 and loss is tensor([0.6172], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 528 and loss is tensor([0.5676], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 529 and loss is tensor([0.6807], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 530 and loss is tensor([0.6333], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 531 and loss is tensor([0.6466], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 532 and loss is tensor([0.6323], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 533 and loss is tensor([0.6120], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 534 and loss is tensor([0.6397], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 535 and loss is tensor([0.7362], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 536 and loss is tensor([0.5875], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 537 and loss is tensor([0.6575], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 538 and loss is tensor([0.5793], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 539 and loss is tensor([0.5849], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 540 and loss is tensor([0.6479], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 541 and loss is tensor([0.6289], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 542 and loss is tensor([0.6498], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 543 and loss is tensor([0.5840], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 544 and loss is tensor([0.5859], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 545 and loss is tensor([0.6035], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 546 and loss is tensor([0.6047], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 547 and loss is tensor([0.6066], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 548 and loss is tensor([0.6041], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 549 and loss is tensor([0.6357], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 550 and loss is tensor([0.6105], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 551 and loss is tensor([0.6075], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 552 and loss is tensor([0.6040], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 553 and loss is tensor([0.6535], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 554 and loss is tensor([0.6249], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 555 and loss is tensor([0.6492], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 556 and loss is tensor([0.6417], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 557 and loss is tensor([0.6306], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 558 and loss is tensor([0.5921], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 559 and loss is tensor([0.5774], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 560 and loss is tensor([0.5908], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 561 and loss is tensor([0.5934], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 562 and loss is tensor([0.6564], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 563 and loss is tensor([0.6192], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 564 and loss is tensor([0.5941], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 565 and loss is tensor([0.6209], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 566 and loss is tensor([0.6270], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 567 and loss is tensor([0.6741], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 568 and loss is tensor([0.6081], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 569 and loss is tensor([0.6136], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 570 and loss is tensor([0.5360], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 571 and loss is tensor([0.6366], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 572 and loss is tensor([0.5662], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 573 and loss is tensor([0.6427], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 574 and loss is tensor([0.5916], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 575 and loss is tensor([0.5723], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 576 and loss is tensor([0.6083], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 577 and loss is tensor([0.6351], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 578 and loss is tensor([0.6316], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 579 and loss is tensor([0.5818], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 580 and loss is tensor([0.6301], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 581 and loss is tensor([0.5775], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 582 and loss is tensor([0.6470], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 583 and loss is tensor([0.6352], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 584 and loss is tensor([0.5577], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 585 and loss is tensor([0.5795], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 586 and loss is tensor([0.6186], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 587 and loss is tensor([0.6349], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 588 and loss is tensor([0.6365], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 589 and loss is tensor([0.6621], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 590 and loss is tensor([0.6784], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 591 and loss is tensor([0.5752], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 592 and loss is tensor([0.6244], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 593 and loss is tensor([0.6007], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 594 and loss is tensor([0.6092], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 595 and loss is tensor([0.6448], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 596 and loss is tensor([0.6237], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 597 and loss is tensor([0.6037], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 598 and loss is tensor([0.5806], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 599 and loss is tensor([0.5140], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 600 and loss is tensor([0.5960], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 601 and loss is tensor([0.5800], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 602 and loss is tensor([0.5826], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 603 and loss is tensor([0.6251], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 604 and loss is tensor([0.6141], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 605 and loss is tensor([0.6724], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 606 and loss is tensor([0.5868], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 607 and loss is tensor([0.5842], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 608 and loss is tensor([0.6601], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 609 and loss is tensor([0.5957], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 610 and loss is tensor([0.5795], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 611 and loss is tensor([0.6596], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 612 and loss is tensor([0.5692], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 613 and loss is tensor([0.6286], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 614 and loss is tensor([0.6116], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 615 and loss is tensor([0.5364], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 616 and loss is tensor([0.5814], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 617 and loss is tensor([0.5875], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 618 and loss is tensor([0.6403], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 619 and loss is tensor([0.5724], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 620 and loss is tensor([0.5926], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 621 and loss is tensor([0.6012], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 622 and loss is tensor([0.6060], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 623 and loss is tensor([0.6357], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 624 and loss is tensor([0.6054], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 625 and loss is tensor([0.5068], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 626 and loss is tensor([0.6499], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 627 and loss is tensor([0.5480], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 628 and loss is tensor([0.5986], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 629 and loss is tensor([0.6348], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 630 and loss is tensor([0.6693], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 631 and loss is tensor([0.5551], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 632 and loss is tensor([0.5801], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 633 and loss is tensor([0.5876], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 634 and loss is tensor([0.6021], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 635 and loss is tensor([0.5903], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 636 and loss is tensor([0.5698], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 637 and loss is tensor([0.5303], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 638 and loss is tensor([0.6232], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 639 and loss is tensor([0.5525], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 640 and loss is tensor([0.6236], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 641 and loss is tensor([0.5897], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 642 and loss is tensor([0.5135], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 643 and loss is tensor([0.5742], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 644 and loss is tensor([0.5332], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 645 and loss is tensor([0.5606], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 646 and loss is tensor([0.5882], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 647 and loss is tensor([0.5144], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 648 and loss is tensor([0.6376], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 649 and loss is tensor([0.5838], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 650 and loss is tensor([0.5598], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 651 and loss is tensor([0.5545], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 652 and loss is tensor([0.5204], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 653 and loss is tensor([0.5755], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 654 and loss is tensor([0.5920], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 655 and loss is tensor([0.5907], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 656 and loss is tensor([0.5909], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 657 and loss is tensor([0.6074], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 658 and loss is tensor([0.5641], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 659 and loss is tensor([0.5128], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 660 and loss is tensor([0.6264], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 661 and loss is tensor([0.5566], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 662 and loss is tensor([0.6138], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 663 and loss is tensor([0.5773], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 664 and loss is tensor([0.6750], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 665 and loss is tensor([0.5753], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 666 and loss is tensor([0.6436], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 667 and loss is tensor([0.5657], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 668 and loss is tensor([0.5611], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 669 and loss is tensor([0.5918], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 670 and loss is tensor([0.5651], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 671 and loss is tensor([0.4730], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 672 and loss is tensor([0.4773], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 673 and loss is tensor([0.5234], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 674 and loss is tensor([0.5722], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 675 and loss is tensor([0.6329], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 676 and loss is tensor([0.5303], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 677 and loss is tensor([0.5162], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 678 and loss is tensor([0.5286], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 679 and loss is tensor([0.5966], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 680 and loss is tensor([0.6240], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 681 and loss is tensor([0.5777], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 682 and loss is tensor([0.6087], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 683 and loss is tensor([0.6111], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 684 and loss is tensor([0.5907], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 685 and loss is tensor([0.6237], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 686 and loss is tensor([0.5930], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 687 and loss is tensor([0.5896], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 688 and loss is tensor([0.5329], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 689 and loss is tensor([0.6034], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 690 and loss is tensor([0.5377], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 691 and loss is tensor([0.5294], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 692 and loss is tensor([0.5695], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 693 and loss is tensor([0.5544], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 694 and loss is tensor([0.5485], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 695 and loss is tensor([0.6504], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 696 and loss is tensor([0.5118], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 697 and loss is tensor([0.5466], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 698 and loss is tensor([0.5791], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 699 and loss is tensor([0.5761], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 700 and loss is tensor([0.5435], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 701 and loss is tensor([0.5855], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 702 and loss is tensor([0.5722], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 703 and loss is tensor([0.5851], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 704 and loss is tensor([0.6492], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 705 and loss is tensor([0.5039], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 706 and loss is tensor([0.6140], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 707 and loss is tensor([0.5835], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 708 and loss is tensor([0.5246], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 709 and loss is tensor([0.5712], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 710 and loss is tensor([0.6237], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 711 and loss is tensor([0.5297], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 712 and loss is tensor([0.5425], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 713 and loss is tensor([0.5719], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 714 and loss is tensor([0.5566], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 715 and loss is tensor([0.6478], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 716 and loss is tensor([0.5838], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 717 and loss is tensor([0.5775], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 718 and loss is tensor([0.5508], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 719 and loss is tensor([0.5815], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 720 and loss is tensor([0.6052], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 721 and loss is tensor([0.5004], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 722 and loss is tensor([0.5602], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 723 and loss is tensor([0.5668], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 724 and loss is tensor([0.5848], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 725 and loss is tensor([0.5263], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 726 and loss is tensor([0.5332], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 727 and loss is tensor([0.5751], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 728 and loss is tensor([0.5968], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 729 and loss is tensor([0.5905], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 730 and loss is tensor([0.5170], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 731 and loss is tensor([0.5961], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 732 and loss is tensor([0.5951], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 733 and loss is tensor([0.5787], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 734 and loss is tensor([0.5628], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 735 and loss is tensor([0.5437], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 736 and loss is tensor([0.5814], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 737 and loss is tensor([0.6051], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 738 and loss is tensor([0.5054], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 739 and loss is tensor([0.5620], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 740 and loss is tensor([0.5848], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 741 and loss is tensor([0.6357], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 742 and loss is tensor([0.5225], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 743 and loss is tensor([0.5604], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 744 and loss is tensor([0.5469], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 745 and loss is tensor([0.5389], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 746 and loss is tensor([0.5392], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 747 and loss is tensor([0.5093], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 748 and loss is tensor([0.5692], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 749 and loss is tensor([0.5950], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 750 and loss is tensor([0.5538], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 751 and loss is tensor([0.5459], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 752 and loss is tensor([0.5582], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 753 and loss is tensor([0.5407], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 754 and loss is tensor([0.6470], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 755 and loss is tensor([0.5042], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 756 and loss is tensor([0.5575], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 757 and loss is tensor([0.4877], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 758 and loss is tensor([0.5334], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 759 and loss is tensor([0.5394], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 760 and loss is tensor([0.5398], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 761 and loss is tensor([0.5201], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 762 and loss is tensor([0.6050], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 763 and loss is tensor([0.5129], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 764 and loss is tensor([0.6060], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 765 and loss is tensor([0.5621], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 766 and loss is tensor([0.5562], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 767 and loss is tensor([0.5172], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 768 and loss is tensor([0.5997], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 769 and loss is tensor([0.5911], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 770 and loss is tensor([0.5734], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 771 and loss is tensor([0.5656], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 772 and loss is tensor([0.5532], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 773 and loss is tensor([0.4756], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 774 and loss is tensor([0.5623], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 775 and loss is tensor([0.6321], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 776 and loss is tensor([0.4845], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 777 and loss is tensor([0.5569], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 778 and loss is tensor([0.5650], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 779 and loss is tensor([0.5896], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 780 and loss is tensor([0.5222], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 781 and loss is tensor([0.5797], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 782 and loss is tensor([0.5912], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 783 and loss is tensor([0.5486], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 784 and loss is tensor([0.5311], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 785 and loss is tensor([0.6178], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 786 and loss is tensor([0.5459], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 787 and loss is tensor([0.6209], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 788 and loss is tensor([0.5607], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 789 and loss is tensor([0.4708], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 790 and loss is tensor([0.5271], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 791 and loss is tensor([0.5299], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 792 and loss is tensor([0.5794], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 793 and loss is tensor([0.5774], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 794 and loss is tensor([0.5135], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 795 and loss is tensor([0.5710], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 796 and loss is tensor([0.5909], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 797 and loss is tensor([0.4809], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 798 and loss is tensor([0.5121], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 799 and loss is tensor([0.5172], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 800 and loss is tensor([0.5003], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 801 and loss is tensor([0.5308], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 802 and loss is tensor([0.5369], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 803 and loss is tensor([0.5883], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 804 and loss is tensor([0.5487], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 805 and loss is tensor([0.5374], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 806 and loss is tensor([0.6130], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 807 and loss is tensor([0.5820], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 808 and loss is tensor([0.5854], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 809 and loss is tensor([0.5418], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 810 and loss is tensor([0.5206], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 811 and loss is tensor([0.5421], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 812 and loss is tensor([0.5984], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 813 and loss is tensor([0.4888], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 814 and loss is tensor([0.4869], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 815 and loss is tensor([0.5597], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 816 and loss is tensor([0.5883], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 817 and loss is tensor([0.5220], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 818 and loss is tensor([0.5075], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 819 and loss is tensor([0.5811], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 820 and loss is tensor([0.5176], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 821 and loss is tensor([0.5853], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 822 and loss is tensor([0.6128], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 823 and loss is tensor([0.5567], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 824 and loss is tensor([0.5664], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 825 and loss is tensor([0.5101], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 826 and loss is tensor([0.5650], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 827 and loss is tensor([0.4908], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 828 and loss is tensor([0.5794], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 829 and loss is tensor([0.5325], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 830 and loss is tensor([0.5656], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 831 and loss is tensor([0.5299], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 832 and loss is tensor([0.5088], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 833 and loss is tensor([0.4992], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 834 and loss is tensor([0.5065], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 835 and loss is tensor([0.5360], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 836 and loss is tensor([0.5379], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 837 and loss is tensor([0.4668], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 838 and loss is tensor([0.4931], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 839 and loss is tensor([0.6284], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 840 and loss is tensor([0.5396], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 841 and loss is tensor([0.5540], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 842 and loss is tensor([0.4925], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 843 and loss is tensor([0.5459], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 844 and loss is tensor([0.5360], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 845 and loss is tensor([0.5580], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 846 and loss is tensor([0.5755], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 847 and loss is tensor([0.5490], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 848 and loss is tensor([0.5519], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 849 and loss is tensor([0.5580], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 850 and loss is tensor([0.5504], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 851 and loss is tensor([0.5115], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 852 and loss is tensor([0.5279], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 853 and loss is tensor([0.5331], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 854 and loss is tensor([0.5495], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 855 and loss is tensor([0.5291], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 856 and loss is tensor([0.5891], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 857 and loss is tensor([0.5738], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 858 and loss is tensor([0.4809], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 859 and loss is tensor([0.4840], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 860 and loss is tensor([0.5718], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 861 and loss is tensor([0.5549], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 862 and loss is tensor([0.5179], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 863 and loss is tensor([0.5108], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 864 and loss is tensor([0.5751], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 865 and loss is tensor([0.5380], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 866 and loss is tensor([0.5054], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 867 and loss is tensor([0.5035], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 868 and loss is tensor([0.5416], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 869 and loss is tensor([0.5043], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 870 and loss is tensor([0.4939], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 871 and loss is tensor([0.5372], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 872 and loss is tensor([0.5373], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 873 and loss is tensor([0.5054], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 874 and loss is tensor([0.5084], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 875 and loss is tensor([0.5107], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 876 and loss is tensor([0.4829], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 877 and loss is tensor([0.5441], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 878 and loss is tensor([0.5005], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 879 and loss is tensor([0.4875], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 880 and loss is tensor([0.5388], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 881 and loss is tensor([0.4630], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 882 and loss is tensor([0.5316], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 883 and loss is tensor([0.4866], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 884 and loss is tensor([0.4651], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 885 and loss is tensor([0.5692], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 886 and loss is tensor([0.5438], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 887 and loss is tensor([0.4940], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 888 and loss is tensor([0.5853], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 889 and loss is tensor([0.5077], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 890 and loss is tensor([0.4955], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 891 and loss is tensor([0.5471], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 892 and loss is tensor([0.5988], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 893 and loss is tensor([0.4859], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 894 and loss is tensor([0.5269], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 895 and loss is tensor([0.5229], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 896 and loss is tensor([0.4635], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 897 and loss is tensor([0.5176], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 898 and loss is tensor([0.5528], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 899 and loss is tensor([0.5025], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 900 and loss is tensor([0.5234], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 901 and loss is tensor([0.4906], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 902 and loss is tensor([0.4975], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 903 and loss is tensor([0.5637], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 904 and loss is tensor([0.5986], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 905 and loss is tensor([0.5096], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 906 and loss is tensor([0.5118], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 907 and loss is tensor([0.4697], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 908 and loss is tensor([0.4692], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 909 and loss is tensor([0.5574], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 910 and loss is tensor([0.4632], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 911 and loss is tensor([0.5167], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 912 and loss is tensor([0.5290], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 913 and loss is tensor([0.5074], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 914 and loss is tensor([0.5827], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 915 and loss is tensor([0.4905], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 916 and loss is tensor([0.5048], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 917 and loss is tensor([0.5186], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 918 and loss is tensor([0.5126], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 919 and loss is tensor([0.4798], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 920 and loss is tensor([0.4417], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 921 and loss is tensor([0.5358], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 922 and loss is tensor([0.5603], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 923 and loss is tensor([0.5119], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 924 and loss is tensor([0.4929], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 925 and loss is tensor([0.5143], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 926 and loss is tensor([0.5334], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 927 and loss is tensor([0.4890], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 928 and loss is tensor([0.5591], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 929 and loss is tensor([0.5180], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 930 and loss is tensor([0.5327], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 931 and loss is tensor([0.5213], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 932 and loss is tensor([0.4938], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 933 and loss is tensor([0.5861], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 934 and loss is tensor([0.4875], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 935 and loss is tensor([0.4786], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 936 and loss is tensor([0.4921], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 937 and loss is tensor([0.4809], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 938 and loss is tensor([0.4617], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 939 and loss is tensor([0.5070], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 940 and loss is tensor([0.4776], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 941 and loss is tensor([0.5159], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 942 and loss is tensor([0.5316], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 943 and loss is tensor([0.5444], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 944 and loss is tensor([0.5731], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 945 and loss is tensor([0.5779], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 946 and loss is tensor([0.5125], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 947 and loss is tensor([0.4519], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 948 and loss is tensor([0.5038], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 949 and loss is tensor([0.4554], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 950 and loss is tensor([0.5467], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 951 and loss is tensor([0.5520], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 952 and loss is tensor([0.5144], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 953 and loss is tensor([0.5349], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 954 and loss is tensor([0.5092], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 955 and loss is tensor([0.5861], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 956 and loss is tensor([0.5826], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 957 and loss is tensor([0.5493], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 958 and loss is tensor([0.4788], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 959 and loss is tensor([0.5427], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 960 and loss is tensor([0.4522], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 961 and loss is tensor([0.5669], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 962 and loss is tensor([0.5168], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 963 and loss is tensor([0.5087], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 964 and loss is tensor([0.6007], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 965 and loss is tensor([0.4975], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 966 and loss is tensor([0.5625], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 967 and loss is tensor([0.5408], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 968 and loss is tensor([0.4974], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 969 and loss is tensor([0.4272], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 970 and loss is tensor([0.5461], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 971 and loss is tensor([0.4959], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 972 and loss is tensor([0.5011], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 973 and loss is tensor([0.4802], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 974 and loss is tensor([0.5282], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 975 and loss is tensor([0.4749], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 976 and loss is tensor([0.5389], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 977 and loss is tensor([0.4503], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 978 and loss is tensor([0.5017], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 979 and loss is tensor([0.5354], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 980 and loss is tensor([0.5433], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 981 and loss is tensor([0.5093], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 982 and loss is tensor([0.5585], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 983 and loss is tensor([0.4869], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 984 and loss is tensor([0.5846], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 985 and loss is tensor([0.5529], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 986 and loss is tensor([0.4535], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 987 and loss is tensor([0.3928], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 988 and loss is tensor([0.4918], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 989 and loss is tensor([0.5050], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 990 and loss is tensor([0.4945], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 991 and loss is tensor([0.4767], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 992 and loss is tensor([0.5286], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 993 and loss is tensor([0.4422], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 994 and loss is tensor([0.5646], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 995 and loss is tensor([0.5021], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 996 and loss is tensor([0.4760], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 997 and loss is tensor([0.5708], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 998 and loss is tensor([0.5420], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 999 and loss is tensor([0.4767], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1000 and loss is tensor([0.5303], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1001 and loss is tensor([0.5131], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 1002 and loss is tensor([0.4890], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1003 and loss is tensor([0.5145], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1004 and loss is tensor([0.4917], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1005 and loss is tensor([0.4633], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1006 and loss is tensor([0.5073], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1007 and loss is tensor([0.4799], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1008 and loss is tensor([0.4775], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1009 and loss is tensor([0.5677], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1010 and loss is tensor([0.4807], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1011 and loss is tensor([0.5088], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1012 and loss is tensor([0.4699], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1013 and loss is tensor([0.5588], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1014 and loss is tensor([0.4914], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1015 and loss is tensor([0.4890], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1016 and loss is tensor([0.4496], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1017 and loss is tensor([0.5144], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1018 and loss is tensor([0.4872], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1019 and loss is tensor([0.4395], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1020 and loss is tensor([0.4875], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1021 and loss is tensor([0.4433], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1022 and loss is tensor([0.4472], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1023 and loss is tensor([0.5870], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1024 and loss is tensor([0.4740], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1025 and loss is tensor([0.5286], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1026 and loss is tensor([0.4727], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1027 and loss is tensor([0.4733], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1028 and loss is tensor([0.5140], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1029 and loss is tensor([0.4731], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1030 and loss is tensor([0.5214], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1031 and loss is tensor([0.5039], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1032 and loss is tensor([0.5044], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1033 and loss is tensor([0.5060], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1034 and loss is tensor([0.5148], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1035 and loss is tensor([0.5201], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1036 and loss is tensor([0.4770], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1037 and loss is tensor([0.5354], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1038 and loss is tensor([0.5217], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1039 and loss is tensor([0.5335], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1040 and loss is tensor([0.5613], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1041 and loss is tensor([0.5316], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1042 and loss is tensor([0.5320], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1043 and loss is tensor([0.5205], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1044 and loss is tensor([0.4440], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1045 and loss is tensor([0.4887], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1046 and loss is tensor([0.4562], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1047 and loss is tensor([0.5467], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1048 and loss is tensor([0.5031], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1049 and loss is tensor([0.4972], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1050 and loss is tensor([0.5029], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1051 and loss is tensor([0.5997], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1052 and loss is tensor([0.5052], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1053 and loss is tensor([0.5152], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1054 and loss is tensor([0.4207], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1055 and loss is tensor([0.4423], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1056 and loss is tensor([0.4547], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1057 and loss is tensor([0.4736], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1058 and loss is tensor([0.5030], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1059 and loss is tensor([0.4804], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1060 and loss is tensor([0.5116], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1061 and loss is tensor([0.4562], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1062 and loss is tensor([0.5009], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1063 and loss is tensor([0.4143], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1064 and loss is tensor([0.4818], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1065 and loss is tensor([0.4647], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1066 and loss is tensor([0.5185], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1067 and loss is tensor([0.5284], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1068 and loss is tensor([0.5040], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1069 and loss is tensor([0.5025], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1070 and loss is tensor([0.4710], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1071 and loss is tensor([0.4784], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1072 and loss is tensor([0.5028], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1073 and loss is tensor([0.4902], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1074 and loss is tensor([0.4619], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1075 and loss is tensor([0.4859], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1076 and loss is tensor([0.5698], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1077 and loss is tensor([0.5068], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1078 and loss is tensor([0.5462], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1079 and loss is tensor([0.5338], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1080 and loss is tensor([0.4818], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1081 and loss is tensor([0.4961], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1082 and loss is tensor([0.5429], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1083 and loss is tensor([0.5185], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1084 and loss is tensor([0.5133], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1085 and loss is tensor([0.5429], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1086 and loss is tensor([0.4544], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1087 and loss is tensor([0.4925], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1088 and loss is tensor([0.4783], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1089 and loss is tensor([0.5397], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1090 and loss is tensor([0.4831], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1091 and loss is tensor([0.4845], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1092 and loss is tensor([0.4666], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1093 and loss is tensor([0.5500], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1094 and loss is tensor([0.5055], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1095 and loss is tensor([0.4066], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1096 and loss is tensor([0.4522], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1097 and loss is tensor([0.4602], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1098 and loss is tensor([0.5670], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1099 and loss is tensor([0.5484], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1100 and loss is tensor([0.5765], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is: 1101 and loss is tensor([0.4701], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1102 and loss is tensor([0.4066], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1103 and loss is tensor([0.5064], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1104 and loss is tensor([0.4687], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1105 and loss is tensor([0.5751], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1106 and loss is tensor([0.4774], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1107 and loss is tensor([0.5098], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1108 and loss is tensor([0.5293], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1109 and loss is tensor([0.4969], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1110 and loss is tensor([0.4218], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1111 and loss is tensor([0.5340], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1112 and loss is tensor([0.5388], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1113 and loss is tensor([0.5315], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1114 and loss is tensor([0.4221], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1115 and loss is tensor([0.5253], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1116 and loss is tensor([0.6445], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1117 and loss is tensor([0.4695], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1118 and loss is tensor([0.4267], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1119 and loss is tensor([0.4431], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1120 and loss is tensor([0.5134], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1121 and loss is tensor([0.4983], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1122 and loss is tensor([0.4403], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1123 and loss is tensor([0.4842], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1124 and loss is tensor([0.5393], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1125 and loss is tensor([0.4380], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1126 and loss is tensor([0.5233], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1127 and loss is tensor([0.4773], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1128 and loss is tensor([0.4491], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1129 and loss is tensor([0.5378], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1130 and loss is tensor([0.4382], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1131 and loss is tensor([0.4877], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1132 and loss is tensor([0.5243], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1133 and loss is tensor([0.4602], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1134 and loss is tensor([0.5410], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1135 and loss is tensor([0.4617], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1136 and loss is tensor([0.4696], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1137 and loss is tensor([0.4880], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1138 and loss is tensor([0.4859], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1139 and loss is tensor([0.5337], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1140 and loss is tensor([0.5521], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1141 and loss is tensor([0.5143], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1142 and loss is tensor([0.4372], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1143 and loss is tensor([0.4899], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1144 and loss is tensor([0.5089], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1145 and loss is tensor([0.4926], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1146 and loss is tensor([0.4401], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1147 and loss is tensor([0.5010], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1148 and loss is tensor([0.5851], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1149 and loss is tensor([0.5126], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1150 and loss is tensor([0.4726], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1151 and loss is tensor([0.5003], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1152 and loss is tensor([0.5037], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1153 and loss is tensor([0.4354], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1154 and loss is tensor([0.4756], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1155 and loss is tensor([0.4619], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1156 and loss is tensor([0.4877], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1157 and loss is tensor([0.5397], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1158 and loss is tensor([0.4347], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1159 and loss is tensor([0.5064], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1160 and loss is tensor([0.5295], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1161 and loss is tensor([0.5036], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1162 and loss is tensor([0.4512], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1163 and loss is tensor([0.4883], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1164 and loss is tensor([0.5770], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1165 and loss is tensor([0.4611], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1166 and loss is tensor([0.5075], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1167 and loss is tensor([0.4833], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1168 and loss is tensor([0.4837], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1169 and loss is tensor([0.4891], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1170 and loss is tensor([0.4136], grad_fn=<AddBackward0>)\n",
      "The number of epochs is: 1171 and loss is tensor([0.4783], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-c2496095fb13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-7edce6ccb0d6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# gradient cliping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = Model()\n",
    "# for epoch in range(50001):\n",
    "#     model.train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n",
      "../Datasets/cat/test/656.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Model:\n",
    "- Using test dataset, get first test seq stroke and first image\n",
    "                    --> Plot the first seq stroke\n",
    "                    --> Plot the first sketch after passing through our saved encoder + decoder\n",
    "- Show images side by side\n",
    "\"\"\"\n",
    "model = Model()\n",
    "\n",
    "# SketchRNN[sequence] -> Sketch\n",
    "seqEncoder = EncoderRNN()\n",
    "saved_encoder = torch.load('../Models/sketchRNN_encoder_0.320616_7000.pt')\n",
    "seqEncoder.load_state_dict(saved_encoder)\n",
    "\n",
    "# PhotoToSketch[\"sketch\"] -> Sketch\n",
    "imageEncoder = ImageEncoder()\n",
    "saved_img_encoder = torch.load('../Models_Complete/sketchRNN_encoder_0.222511_1100.pt')\n",
    "imageEncoder.load_state_dict(saved_img_encoder)\n",
    "\n",
    "decoder = DecoderRNN()\n",
    "saved_decoder = torch.load('../Models/sketchRNN_decoder_0.320616_7000.pt')\n",
    "decoder.load_state_dict(saved_decoder)\n",
    "\n",
    "# Data comes from test set now\n",
    "dataset = np.load(hp.data_location, encoding='latin1')\n",
    "data = dataset['test']\n",
    "data = purify(data)\n",
    "data = normalize(data)\n",
    "Nmax = max_size(data)\n",
    "\n",
    "# Choose 5 sketches to test\n",
    "\n",
    "def test():\n",
    "    # sequence from test dataset\n",
    "    sketch, lengths, indexes = make_batch(1)\n",
    "\n",
    "    z_1, _, _ = seqEncoder(sketch, 1)\n",
    "\n",
    "    # pass this to function to plot in grid\n",
    "    seq_1 = model.getStrokesToPlot(z_1)\n",
    "    \n",
    "    img_paths = []\n",
    "    for i in indexes:\n",
    "        img_paths.append(f\"{hp.test_photo_image_path}{i}.png\")\n",
    "        \n",
    "    # Get image encoder zs\n",
    "    z_2 = imageEncoder(img_paths)\n",
    "    seq_2 = model.getStrokesToPlot(z_2)\n",
    "    \n",
    "    plotImages(img_paths[0], seq_1, seq_2)\n",
    "    \n",
    "def plotImages(original_sketch, rnn_output, pTS_output):\n",
    "    show_image(original_sketch)\n",
    "    make_image(rnn_output)\n",
    "    make_image(pTS_output)\n",
    "\n",
    "def show_image(image):\n",
    "    print(image)\n",
    "    img = mpimg.imread(image)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN()\n",
    "decder = DecoderRNN()\n",
    "encoder.load(../Models/sketchRNN_encoder_0.320616_7000.pt)\n",
    "decoder.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9336\n"
     ]
    }
   ],
   "source": [
    "# for i in range(69999):\n",
    "#     if os.path.isfile(f\"{train_photo_image_path}{i}.png\") == False:\n",
    "#         print(i)\n",
    "#         break\n",
    "        \n",
    "# # remember - 9336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bottleneck_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c7dfc44ca3bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use conditional generation function to test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# not the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Models/sketchRNN_encoder_0.497555_1600.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../Models/sketchRNN_decoder_0.497555_1600.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-aa3c79e16957>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msaved_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Models/sketchRNN_encoder_0.320616_7000.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoderRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-36577d3295ff>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;31m# 0 or 1, black and white\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_h1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottleneck_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bottleneck_size' is not defined"
     ]
    }
   ],
   "source": [
    "# # Use conditional generation function to test model\n",
    "\n",
    "# model = Model()\n",
    "# # not the best model\n",
    "# model.load('../Models/sketchRNN_encoder_0.497555_1600.pt','../Models/sketchRNN_decoder_0.497555_1600.pt')\n",
    "# for i in range(50001):\n",
    "#     model.conditional_generation(i)\n",
    "    \n",
    "# # choose best model\n",
    "# # \n",
    "# # [sketch, latent vector]\n",
    "# # choose best 40 sketches -> save zs in set\n",
    "# # for each sketch in \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
