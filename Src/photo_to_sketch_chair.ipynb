{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "np.load.__defaults__=(None, True, True, 'ASCII')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams():\n",
    "    def __init__(self):\n",
    "        self.image_size = 28\n",
    "        self.bottleneck_size = 128\n",
    "        self.enc_hidden_size = 256\n",
    "        self.dec_hidden_size = 512\n",
    "        self.Nz = 128\n",
    "        self.M = 20\n",
    "        self.dropout = 0.9\n",
    "        self.batch_size = 100\n",
    "        self.eta_min = 0.01\n",
    "        self.R = 0.99995\n",
    "        self.KL_min = 0.2\n",
    "        self.wKL = 0.5\n",
    "        self.lr = 0.001\n",
    "        self.lr_decay = 0.9999\n",
    "        self.min_lr = 0.00001\n",
    "        self.grad_clip = 1.\n",
    "        self.temperature = 0.4\n",
    "        self.max_seq_length = 200\n",
    "\n",
    "hp = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this variable in conditional_generation\n",
    "Nmax = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(400, 128)  # 6*6 from image dimension\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, image_paths):\n",
    "        all_zs = torch.empty(0, 128)\n",
    "        # Max pooling over a (2, 2) window\n",
    "        for i, data in enumerate(image_paths):\n",
    "            img = mpimg.imread(data)\n",
    "            gray = rgb2gray(img)\n",
    "            x = torch.from_numpy(gray)\n",
    "            # change (28,28) to (1,1,28,28)\n",
    "            x = torch.unsqueeze(x,0)\n",
    "            x = torch.unsqueeze(x,0)\n",
    "            #print(f\"dimension of x {x.shape}\")\n",
    "            x = F.max_pool2d(F.relu(self.conv1(x.float())), (2, 2))\n",
    "            # If the size is a square you can only specify a single number\n",
    "            x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            \n",
    "            #print(x.shape) #1 x 400\n",
    "            x = self.fc1(x)\n",
    "            #print(all_zs.shape)\n",
    "            all_zs = torch.cat([all_zs, x], dim=0)\n",
    "            #all_zs.cat(x)\n",
    "        return all_zs\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # bidirectional lstm:\n",
    "        self.lstm = nn.LSTM(5, hp.enc_hidden_size, \\\n",
    "            dropout=hp.dropout, bidirectional=True)\n",
    "        # create mu and sigma from lstm's last output:\n",
    "        self.fc_mu = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
    "        self.fc_sigma = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
    "        # active dropout:\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, inputs, batch_size, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            # then must init with zeros\n",
    "            if use_cuda:\n",
    "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size).cuda()\n",
    "                cell = torch.zeros(2, batch_size, hp.enc_hidden_size).cuda()\n",
    "            else:\n",
    "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size)\n",
    "                cell = torch.zeros(2, batch_size, hp.enc_hidden_size)\n",
    "            hidden_cell = (hidden, cell)\n",
    "        _, (hidden,cell) = self.lstm(inputs.float(), hidden_cell)\n",
    "        # hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\n",
    "        hidden_forward, hidden_backward = torch.split(hidden,1,0)\n",
    "        hidden_cat = torch.cat([hidden_forward.squeeze(0), hidden_backward.squeeze(0)],1)\n",
    "        # mu and sigma:\n",
    "        mu = self.fc_mu(hidden_cat)\n",
    "        sigma_hat = self.fc_sigma(hidden_cat)\n",
    "        sigma = torch.exp(sigma_hat/2.)\n",
    "        # N ~ N(0,1)\n",
    "        z_size = mu.size()\n",
    "                                   \n",
    "        if use_cuda:\n",
    "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size)).cuda()\n",
    "        else:\n",
    "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size))\n",
    "        z = mu + sigma*N\n",
    "        # mu and sigma_hat are needed for LKL loss\n",
    "        return z, mu, sigma_hat #[100,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # to init hidden and cell from z:\n",
    "        self.fc_hc = nn.Linear(hp.Nz, 2*hp.dec_hidden_size)\n",
    "        # unidirectional lstm:\n",
    "        self.lstm = nn.LSTM(hp.Nz+5, hp.dec_hidden_size, dropout=hp.dropout)\n",
    "        # create proba distribution parameters from hiddens:\n",
    "        self.fc_params = nn.Linear(hp.dec_hidden_size,6*hp.M+3)\n",
    "\n",
    "    def forward(self, inputs, z, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            # then we must init from z\n",
    "            hidden,cell = torch.split(F.tanh(self.fc_hc(z)),hp.dec_hidden_size,1)\n",
    "            hidden_cell = (hidden.unsqueeze(0).contiguous(), cell.unsqueeze(0).contiguous())\n",
    "        outputs,(hidden,cell) = self.lstm(inputs, hidden_cell)\n",
    "        # in training we feed the lstm with the whole input in one shot\n",
    "        # and use all outputs contained in 'outputs', while in generate\n",
    "        # mode we just feed with the last generated sample:\n",
    "        if self.training:\n",
    "            y = self.fc_params(outputs.view(-1, hp.dec_hidden_size))\n",
    "        else:\n",
    "            y = self.fc_params(hidden.view(-1, hp.dec_hidden_size))\n",
    "        # separate pen and mixture params:\n",
    "        params = torch.split(y,6,1)\n",
    "        params_mixture = torch.stack(params[:-1]) # trajectory\n",
    "        params_pen = params[-1] # pen up/down\n",
    "        # identify mixture params:\n",
    "        pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy = torch.split(params_mixture,1,2)\n",
    "        # preprocess params::\n",
    "        if self.training:\n",
    "            len_out = Nmax+1\n",
    "        else:\n",
    "            len_out = 1\n",
    "                                   \n",
    "        pi = F.softmax(pi.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_x = torch.exp(sigma_x.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_y = torch.exp(sigma_y.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        rho_xy = torch.tanh(rho_xy.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        mu_x = mu_x.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        mu_y = mu_y.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        q = F.softmax(params_pen).view(len_out,-1,3)\n",
    "        return pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy,q,hidden,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(optimizer):\n",
    "    \"\"\"Decay learning rate by a factor of lr_decay\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['lr']>hp.min_lr:\n",
    "            param_group['lr'] *= hp.lr_decay\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize real images\n",
    "def preprocess_image(dir_in, dir_out):\n",
    "    for img in os.listdir(dir_in):         \n",
    "        img_name = os.path.splitext(img)[0]    # remove extension\n",
    "        image = Image.open(os.path.join(dir_in, img))\n",
    "        new_image = image.resize((28, 28))\n",
    "        new_image.save(f\"{dir_out}/{img_name}.png\")\n",
    "        \n",
    "# resize sketch images\n",
    "def preprocess_sketch(dir_in, dir_out):\n",
    "    for sketch in os.listdir(dir_in):         \n",
    "        sketch_name = os.path.splitext(sketch)[0]    # remove extension\n",
    "        s_image = Image.open(os.path.join(dir_in, sketch))\n",
    "        new_image = s_image.resize((28, 28))\n",
    "        new_image.save(f\"{dir_out}/{sketch_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy, greedy=False):\n",
    "    # inputs must be floats\n",
    "    if greedy:\n",
    "         return mu_x,mu_y\n",
    "    mean = [mu_x, mu_y]\n",
    "    sigma_x *= np.sqrt(hp.temperature)\n",
    "    sigma_y *= np.sqrt(hp.temperature)\n",
    "    cov = [[sigma_x * sigma_x, rho_xy * sigma_x * sigma_y],\\\n",
    "        [rho_xy * sigma_x * sigma_y, sigma_y * sigma_y]]\n",
    "    x = np.random.multivariate_normal(mean, cov, 1)\n",
    "    return x[0][0], x[0][1]    \n",
    "        \n",
    "def make_image(sequence):\n",
    "    \"\"\"plot drawing with separated strokes\"\"\"\n",
    "    strokes = np.split(sequence, np.where(sequence[:,2]>0)[0]+1)\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1,1,1)\n",
    "    for s in strokes:\n",
    "        plt.plot(s[:,0],-s[:,1])\n",
    "    #print(\"Outputting sketch\")\n",
    "    #name = str(epoch)+name+'.jpg'\n",
    "    #plt.savefig(F\"./outputs_complete/{name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel():\n",
    "    def __init__(self):\n",
    "        self.s2s_encoder = ImageEncoder().to(device)\n",
    "        self.p2s_encoder = ImageEncoder().to(device)\n",
    "        self.decoder = DecoderRNN().to(device)\n",
    "        self.p2s_encoder_optimizer = optim.Adam(self.p2s_encoder.parameters(), hp.lr)\n",
    "        self.eta_step = hp.eta_min\n",
    "        self.img_dir = '../Datasets/sketchy_chair/chair_p_train_resized'\n",
    "        self.sketch_dir = '../Datasets/sketchy_chair/chair_s_train_resized'\n",
    "        self.img_paths = []\n",
    "        self.sketch_paths = []\n",
    "            \n",
    "    # For each img, there are multiple sketches. \n",
    "    # e.g. n02121620.png -> n02121620-i.png (i = 1,2,3,...)\n",
    "    \n",
    "    # Add paired paths to img_paths and sketch_paths arrays.  \n",
    "    def process_data(self):\n",
    "        for img in os.listdir(self.img_dir):         \n",
    "            img_name = os.path.splitext(img)[0]    # remove extension\n",
    "            i = 1\n",
    "            while(os.path.exists(f\"{self.sketch_dir}/{img_name}-{i}.png\")):\n",
    "                self.img_paths.append(os.path.join(self.img_dir, img))\n",
    "                sketch = f\"{img_name}-{i}.png\"\n",
    "                self.sketch_paths.append(os.path.join(self.sketch_dir, sketch))\n",
    "                i += 1                                \n",
    "    \n",
    "    # load pre-trained models for training p2s_encoder\n",
    "    def load_for_training(self, s2s_encoder, decoder):\n",
    "        s2s_encoder = torch.load(s2s_encoder)\n",
    "        decoder = torch.load(decoder)\n",
    "        self.s2s_encoder.load_state_dict(s2s_encoder)\n",
    "        self.decoder.load_state_dict(decoder)\n",
    "        \n",
    "    # load the final encoder and decoder for testing the p2s model\n",
    "    def load(self, encoder, decoder):\n",
    "        p2s_encoder = torch.load(encoder)\n",
    "        decoder = torch.load(decoder)\n",
    "        self.p2s_encoder.load_state_dict(p2s_encoder)\n",
    "        self.decoder.load_state_dict(decoder)        \n",
    "            \n",
    "    def train(self, epoch):\n",
    "        self.p2s_encoder.train()\n",
    "        self.decoder.train()\n",
    "        z_target = self.s2s_encoder(self.sketch_paths)\n",
    "        z_pred = self.p2s_encoder(self.img_paths)\n",
    "        \n",
    "        self.p2s_encoder_optimizer.zero_grad()\n",
    "        self.eta_step = 1-(1-hp.eta_min)*hp.R\n",
    "        \n",
    "        loss = self.encoder_loss(z_pred, z_target)\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm(self.p2s_encoder.parameters(), hp.grad_clip)\n",
    "        \n",
    "        self.p2s_encoder_optimizer.step()\n",
    "        \n",
    "        if epoch%1==0:\n",
    "            print(f\"The number of epochs is: {epoch} and loss is {loss}\")\n",
    "            self.p2s_encoder_optimizer = lr_decay(self.p2s_encoder_optimizer)\n",
    "        if epoch%100==0:\n",
    "            self.save(epoch)\n",
    "        \n",
    "    def encoder_loss(self, pred_z, target_z):\n",
    "        criterion = nn.MSELoss()\n",
    "        return criterion(pred_z, target_z)\n",
    "    \n",
    "    def save(self, epoch):\n",
    "        random_number = np.random.rand()\n",
    "        enc_model_name = 'img_encoder_%3f_%d.pt' % (random_number, epoch)\n",
    "        enc_path = F\"../p2s_models/chair/{enc_model_name}\"\n",
    "        torch.save(self.p2s_encoder.state_dict(), enc_path)\n",
    "        \n",
    "    def conditional_generation(self, z):\n",
    "        #batch,lengths = make_batch(1)\n",
    "        # should remove dropouts:\n",
    "        self.p2s_encoder.train(False)\n",
    "        self.decoder.train(False)\n",
    "        # encode:\n",
    "        #z, _, _ = self.encoder(batch, 1)\n",
    "        if use_cuda:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1).cuda())\n",
    "        else:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1))\n",
    "        s = sos\n",
    "        seq_x = []\n",
    "        seq_y = []\n",
    "        seq_z = []\n",
    "        hidden_cell = None\n",
    "        for i in range(Nmax):\n",
    "            input = torch.cat([s,z.unsqueeze(0)],2)\n",
    "            # decode:\n",
    "            self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "                self.rho_xy, self.q, hidden, cell = \\\n",
    "                    self.decoder(input, z, hidden_cell)\n",
    "            hidden_cell = (hidden, cell)\n",
    "            # sample from parameters:\n",
    "            s, dx, dy, pen_down, eos = self.sample_next_state()\n",
    "            #------\n",
    "            seq_x.append(dx)\n",
    "            seq_y.append(dy)\n",
    "            seq_z.append(pen_down)\n",
    "            if eos:\n",
    "                print(i)\n",
    "                break\n",
    "        # visualize result:\n",
    "        x_sample = np.cumsum(seq_x, 0)\n",
    "        y_sample = np.cumsum(seq_y, 0)\n",
    "        z_sample = np.array(seq_z)\n",
    "        sequence = np.stack([x_sample,y_sample,z_sample]).T\n",
    "        make_image(sequence)      \n",
    "        \n",
    "    def sample_next_state(self):\n",
    "        def adjust_temp(pi_pdf):\n",
    "            pi_pdf = np.log(pi_pdf)/hp.temperature\n",
    "            pi_pdf -= pi_pdf.max()\n",
    "            pi_pdf = np.exp(pi_pdf)\n",
    "            pi_pdf /= pi_pdf.sum()\n",
    "            return pi_pdf\n",
    "\n",
    "        # get mixture indice:\n",
    "        pi = self.pi.data[0,0,:].cpu().numpy()\n",
    "        pi = adjust_temp(pi)\n",
    "        pi_idx = np.random.choice(hp.M, p=pi)\n",
    "        # get pen state:\n",
    "        q = self.q.data[0,0,:].cpu().numpy()\n",
    "        q = adjust_temp(q)\n",
    "        q_idx = np.random.choice(3, p=q)\n",
    "        # get mixture params:\n",
    "        mu_x = self.mu_x.data[0,0,pi_idx]\n",
    "        mu_y = self.mu_y.data[0,0,pi_idx]\n",
    "        sigma_x = self.sigma_x.data[0,0,pi_idx]\n",
    "        sigma_y = self.sigma_y.data[0,0,pi_idx]\n",
    "        rho_xy = self.rho_xy.data[0,0,pi_idx]\n",
    "        x,y = sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy,greedy=False)\n",
    "        next_state = torch.zeros(5)\n",
    "        next_state[0] = x\n",
    "        next_state[1] = y\n",
    "        next_state[q_idx+2] = 1\n",
    "        if use_cuda:\n",
    "            return Variable(next_state.cuda()).view(1,1,-1),x,y,q_idx==1,q_idx==2\n",
    "        else:\n",
    "            return Variable(next_state).view(1,1,-1),x,y,q_idx==1,q_idx==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process and train data\n",
    "# preprocess_image('../Datasets/sketchy_chair/chair_p_train', '../Datasets/sketchy_chair/chair_p_train_resized')\n",
    "# preprocess_sketch('../Datasets/sketchy_chair/chair_s_train', '../Datasets/sketchy_chair/chair_s_train_resized')\n",
    "# preprocess_image('../Datasets/sketchy_chair/chair_p_test', '../Datasets/sketchy_chair/chair_p_test_resized')\n",
    "# preprocess_sketch('../Datasets/sketchy_chair/chair_s_test', '../Datasets/sketchy_chair/chair_s_test_resized')\n",
    "\n",
    "# model = NewModel()\n",
    "# model.load_for_training('../Models_Complete_Chairs/sketchRNN_encoder_0.874900_18000.pt', '../Models_Complete_Chairs/sketchRNN_decoder_0.874900_18000.pt')\n",
    "# model.process_data()\n",
    "# for epoch in range(30001):\n",
    "#     model.train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX8ElEQVR4nO3deZRU5ZnH8e9T3dUsTbN2K4sgioABRUdbFFHABD3GGLdEUdySOMElmpnEjGPizJg5jiYuSc6YeHQwEmOCGjWojDFjJEeBGBcaRQRxwYVFtkaQrVm6u575o6ubpu2il7pVt27V73NOHerWvX3fh+v11y9vvfdec3dERCS6YmEXICIi6VGQi4hEnIJcRCTiFOQiIhGnIBcRibjiMBotLy/3oUOHhtG0iEhkLVy4cKO7V7T8PJQgHzp0KFVVVWE0LSISWWa2orXPNbQiIhJxCnIRkYhTkIuIRJyCXEQk4hTkIiIRpyAXEYk4BbmISMSFMo88basWwPt/AbPkB5Z8n1ze533z9fvZtsPr2Xd9WvtKtT7F/gNpq53HpdNt0Y6f7+wxov0/H+8O3fsiks+iGeSfLIR5d4RdhUTB6PPg/N+EXYVIRkUzyE+4quHVyL3h1bDQynvfu12n1tOO9em2RQdq6Whbnf359m5LO/bV2bboxL6are8zFIBZ78/i3jfvZdZZsygrKUMkn0QzyFuyFsMRIi3sqN3Buh3r8MaQF8kj+rJTCoIeaSj5TEEuBcXQv9wk/yjIRUQiTkEuBUFj45LPFORSUDS0IvlIQS4iEnEKcikopmmqkocU5CIiERdIkJvZDDPbYGZLgtifSNA0j1zyWVA98geB0wPal0jG6MtOyUeBBLm7zwM2BbEvERHpmKyNkZvZNDOrMrOq6urqbDUrAmgeueS3rAW5u09390p3r6yoqMhWsyJ7Obwz70We+/VrvF+1PuxqRAKjWStSEBynrKaYuQ/8D+/Mf5LqldvCLkkkMApyKRjbSus48rTTqdv1Fjs++yTsckQCE9T0w0eAl4GRZrbazK4IYr8iQas893ywbnz8xixNSZS8EdSslYvcfYC7x939IHd/IIj9igSlMbRLunenuNt4tm74gPdeeSnkqkSCkR9PCBJpr4RRVHIEXbq8zbyZM+j15hISK1Yy8Ce3hV2ZSKdpjFwKQjwWp3txdzzhmMUYNvbrbK3ewFtvvEbNggVhlyeSFgW5FITLRl/Gqxe/SklRFwD6DRrJ8LEn8vaWjdTU14VcnUh6FORSUMxg5An96TuwlAmXfAsvirHqK5PDLkskLQpyKSjF8SImf2MUQ48sp/eB/Tn2K+fwzoKXWfv+u2GXJtJpCnIpaMefewGlvfvwwoPT8UQi7HJEOkVBLgWtpFt3TrroctYuf5dlL80NuxyRTlGQS8EbPeGLHHjocOY//CC1u3aFXY5IhynIpeBZLMYpl3+b7Zs+5bXZT4RdjkiHKchFgEGHj+Lw8ROpmj2LrdUbwi5HpEMU5CJJJ0/9Bpgxd+Zvwi5FpEMU5CJJPcsrOO6s83jv5fmsXqbHz0p0KMhFmjnurK/Ro185L/z2fk1HlMhQkIs0E+/SlQkXf5MNH33Akrlzwi5HpF0U5CItHH7iBAaO+AJ/e+QhdtfUhF2OSJsU5CItmBmnXP5tarZ8xqtP/iHsckTapCAXaUX/w0YweuJkXn/2aTavWxN2OSL7FdSj3k43s3fNbLmZ3RjEPkXCdtJFlxErjjP3dzPCLkVkv9IOcjMrAu4BvgyMAi4ys1Hp7lckbD369OX4c87ng6pXWPHWorDLEUkpiB75WGC5u3/o7nuAR4GzA9ivSOiO/co59DrgQF787f0k6uvDLkekVUEE+SBgVbPl1cnP9mFm08ysysyqqqurA2hWJPOKS0qYeMkVbFy1gsV/fQ6ATZs2sXXFp9Qs2oAnPOQKRYIJcmvls8+d3e4+3d0r3b2yoqIigGZFsuOwseMYPOpIXnrs9+zavp27776bv8+Zz6ZH9TAKyQ1BBPlqYHCz5YMAfc0vecPMmHT5t9m9fTt/f3xmw4fuYGCx1voxItkVRJAvAIab2SFmVgJcCMwOYL8iOeOAoYdy5JdOY9Hzz+79UCEuOSLtIHf3OuBa4DlgGfCYuy9Nd78iuWb8lEuJd+nasJBQb1xyRyDzyN39WXcf4e7D3P3WIPYpkmu69+zF8edNAWD39u3qkUvO0JWdIh1w9GlnALB940asSEEuuaE47AJEoiRW1PC/TPmxw+h79BdCrkakgXrkIp3QraI3XYf1DrsMEUBBLtIh7g2XSJhpWEVyh4JcpJPWrXuaBVVfo65uO2t37+HxdZv4dE9d2GVJAVKQi3RA8x75zl2r2bp1EbFYCUu27eS6ZStZsWt3yBVKIVKQi3RSfX0NZnFisZKme1LEWr1jhUhmKchFOqB5j7y+fgdFRd0bPk+u19C5hEHTD0U6IB6Pc+WVV1JWVgZ2AOX9vgQ03HoF1DOScOi8E+mAWCzGgAED6NGjBz1Kh9Ov38kAJJJ98s91yPfUwEfzYdt6ampruOK5K1iwbkF2i5a8pyAXCcDeoZUWUb51Dfz2TPhoLj+r+plCXDJCQysiAUg5tBJvuMnW/E1LeWzFLC4fdTnH9T8uq7VJ/lOPXCQAiVQrirvyWSzGzZ88x2G9D+O6Y67LZllSIBTkIgHw5OBKLDm08sziNdzyzNtQ3JVb+/Vhc10Nt510G12KuoRZpuQpBblIABqHVhpHyBeu2MxjC1bx7OoX+b8epVxvYxm8bFNo9Ul+U5CLBKDpy87kn8Uxo44abn3tJ4ypGMMp7w9gzY03hlWe5Dl92SkSgL7xYsb2KqVbUUPfqE9pCQN79uGm8bcwrPcwYi8/oBttScakFeRmdj7wY+ALwFh3rwqiKJGomdi3jIl9y5qWr5l0GNdMOqxpeY0ndNmnZEy6QytLgPOAeQHUIpK/3CGmkUzJjLR65O6+DHRvZpE2JVw9csmYrHURzGyamVWZWVV1dXW2mhXJDe7q8EjGtNkjN7M5QP9WVt3k7k+3tyF3nw5MB6isrPQ2NhfJLxojlwxqM8jdfXI2ChHJZ64xcskgnVki2dBijHzXjlrmPfoe6z7cEmJRki/SCnIzO9fMVgPjgD+Z2XPBlCWSX6yoCCuJNy3X7q7nrRdXs2ntDj5etJBHb76BbZs24rX1rL9nETteXx9itRI16c5aeRJ4MqBaRPLWwNt/mnJdzbatfPLO29Tt3o2XQu2qbSSOKM9idRJ1GloRCZPvnb7b+Bg5oJUnVIikpiAXCUHzCSyW/BLUE87eu7aItJ+CXCRE7o5ZMsg9oRyXTtFNs0RCsbdLbrHk0Eoi0dpqNm7cyObNmykpKSEej+/zKikpobi4eJ+LjWpqPsK9ntLSvfd6kfymIBcJWdPQSvMx8mZJvnjxYubN2//tjBqDfeLEiZR0uZe6um0cV/nHTJQrOUhBLhICs7098aahlUQCi8foO/Vw4gNKm7atrKxk+PDh1NbWUltby549e5ret/ysX79+bNseyl9JQmT79gKyo7Ky0quqdMdbEYDaXbvY8dlmevQrpzgeb/sH2vDGom9QV7ed4yqfCKA6ySVmttDdK1t+rh65SMjiXbvSu/+A4HYYQudMwqVZKyJ5SNPQC4uCXEQk4hTkInlHQyuFRkEuko907/OCoiAXyTOe7JHXJpzbP1zLq59pPmK+U5CL5CVjjyf4xYr1LNiyI+xiJMM0/VAkz4wc8WOcvfdt0bNC85+CXCTPlJYOA2B7XT2gqYiFQEMrInmqce6Kgjz/pfuotzvN7B0zW2xmT5pZ74DqEpE0KcgLR7o98ueBI9x9DPAe8MP0SxKRIDTeR0lD5PkvrSB397+4e11y8RXgoPRLEpEgNPbIY+qT570gx8i/Bfw51Uozm2ZmVWZWVV1dHWCzItKaxsdUqEee/9qctWJmc4D+ray6yd2fTm5zE1AHzEy1H3efDkyHhtvYdqpaEWk33QSxcLQZ5O4+eX/rzexy4EzgSx7Gzc1FpFXNv+xct2UXxUVGeY8uYZYkGZLurJXTgX8FznL3mmBKEpEgNF6qb8DFv36Fm2cvDbcgyZh0x8h/BZQBz5vZIjO7L4CaRCQAXWMxLhnQj5GlXcMuRTIsrSs73V2P6RbJUWXFRdx1+GCgYZilOLEH5v8cYsVQFG/4M+X7OBQV730fK04ux5ttV5TcLsW+9C1r1ugSfZEC0cV3wV//M3sNWlEy2JOhn+qXxH5/YTTfLsUvjwB+Ma3s0ZcZ78zk+srrKSspy94xCoiCXKQAfP/UEfTpFocL10OiFuprIVHf7H3d3lfz5Vbf10J93d73ibrkcmvvO9JOcts9NSnaqW+2XYt2PNH2QUihDvjhMafy8Y61XH3U1QpyEclNZ44Z2GwpD8fME4lm4d/sl8f+fmEkP39gxZ9YvPLP3DHhDg4sPTDsv0mnKMhFJPpiMYiVACUd+rGlG5dy36rn+f5Hh1O59QO4LjPlZZrufigiBeuXb/ySvt36Mml9X7bNmRN2OZ2mHrmIFKw7J97Jmu1riM+7hz2J+rDL6TT1yEWkYJWVlDGy70goKsLrO/+FadgU5CJS8CwWg3r1yEVEoqu4CE+oRy4iElkWK8Lr69reMEcpyEVEimKgMXIRkeiyWBGeqGfntj3MfeRd1n+0NeySOkTTD0Wk4HUdPRqvr2d3TR1L5n5C/0N7ceAhPcMuq90U5CJS8PpcOIU+F05h87odAFjExioiVq6ISOY03nvLInYLXgW5iEhS49MqFeQiIhHV+NThghpaMbNbzGxx8jFvfzGzgW3/lIhIbirUHvmd7j7G3Y8GngH+I/2SRERC0tgjj1aOpxfk7t58smUpTYdBRCR6Eolo9sjTnn5oZrcClwFbgFP2s900YBrAkCFD0m1WRCRwTUMrsWgFeZs9cjObY2ZLWnmdDeDuN7n7YGAmcG2q/bj7dHevdPfKioqK4P4GIiJBaTa08t4rf2PjypXUVteQ2Jnb92Fps0fu7pPbua+HgT8BN6dVkYhISLqVxRk9YRDde8Z54pY7GPfVKQx+awi9vnooZeMHhV1eSunOWhnebPEs4J30yhERCU+viu5MmjqS3v27MemyKxhyxNFA7g+1pDtG/lMzGwkkgBXAVemXJCISruJ4nGPOOJv6rXtYy6s5P40lrSB3968FVYiISK5p/PIz1y+dzPHyRERCVB+NWSwKchGRVDwaVwgpyEVEUvCEeuQiItHWeK16jidljpcnIhKihIZWREQiTUMrIiJR1zi0oh65iEhENQ6tFCnIRUQiqWlopVmOL1++nNtvv521a9eGVNXnpX0bWxGRfBXv352Kq48iXtGt6bNEIsHOnTtJJBIhVrYvBbmISAqxLsV0Obhn2GW0SUMrIiIRpyAXEYk4BbmISCc03RkxByjIRUQiTkEuIhJxCnIRkYgLJMjN7Adm5mZWHsT+RESiYs3aJ9i48YVQa0g7yM1sMHAqsDL9ckREcltpaSkjRoyga9euAHz88b2sW/dUqDUF0SP/BXADe28vIyKStwYNGsTUqVMpL282ABHyTbXSCnIzOwv4xN3fbMe208ysysyqqqur02lWRCSHhN+HbfMSfTObA/RvZdVNwI+A09rTkLtPB6YDVFZWhv83FxEJhAPh9sjbDHJ3n9za52Z2JHAI8KY1/LPiIOB1Mxvr7usCrVJEJIdZrgd5Ku7+FnBA47KZfQxUuvvGAOoSEYmGHBhf0DxyEZE0eBSGVtrL3YcGtS8RkejwsHNcPXIRkfRFePqhiIjsO0h+1dKPueuj7M730BOCRETS0Kf3CfToMbJp+c1tNVnvnyvIRUTSMGrUHfssO2BZvtJTQysiIgHyEL77VJCLiAQojMmICnIRkQCFcX2QglxEJECOZ/1miApyEZEAaYxcRCQPZPsmWgpyEZEANX7ZuXVXLU8sXM2qTTUZb1NBLiISoDFl3TikWxc2bN3NDx5/kzdWfZbxNnVBkIhIgB488lAA3l+/DcjOeLl65CIiGdA4DTGWhSksCnIRkQxIeEOUZ2MqooJcRCQDkjlOTEEuIhJNjT3ybIySpxXkZvZjM/vEzBYlX2cEVZiISJRls0cexKyVX7j7XQHsR0QkbzQGeTZuaauhFRGRDPDkvJWojJFfa2aLzWyGmfVJtZGZTTOzKjOrqq6uDqBZEZHclWjqkWe+rTaD3MzmmNmSVl5nA/cCw4CjgbXAz1Ltx92nu3ulu1dWVFQEVb+ISE7ypumHmU/yNsfI3X1ye3ZkZvcDz6RdkYhIHkg0fdnZLMjXLYH+RwTeVrqzVgY0WzwXWJJeOSIi+aGpR974wVtPwH3jYelTgbeV7qyVO8zsaBquRv0YuDLdgkRE8sGI/mU8/I/HM2pgT1j5Cjx1NQw5EUZ+OfC20gpyd780qEJERPJJz65xTjysHD79AB65CHoNhgtnQnGXwNvS9EMRkUyp2QQPXwA4XPw4dO+bkWZ0G1sRkUyo2wN/uBQ+WwmXPQ39hmWsKQW5iEjQ3OF/vwsr/gbn3Q8Hn5jR5jS0IiIStHl3wZuPwKQfwZgLMt6cglxEJEiLH4cX/gvGXAgTb8hKkwpyEZGgrHgZnr4GDh4PZ92dnevzUZCLiATj0w/g0anQewhM+X1GphmmoiAXEUlX0zRDYOpjGZtmmIpmrYiIpKNuN/zhkuQ0w9kZnWaYioJcRKSz3GH2d2HFS3Der+HgcaGUoaEVEZHOmncnLH4UTrkJxpwfWhkKchGRzlj8OLxwKxx1EUz4l1BLUZCLiHRQzYcvsnP2NXDwSfDV/87aNMNUFOQiIh3x6QdMeeE7/Hv/gTDld1mdZpiKglxEpL1qNsHM8zHAh4zL+jTDVBTkIiLt0TjNcMsqYj0H4SXdw66oSdpBbmbXmdm7ZrbUzO4IoigRkZzSfJrhOfdiJaVNj3LLBWnNIzezU4CzgTHuvtvMDgimLBGRHDL3juQ0w3+DI78OH87EyZ0gT7dHfjXwU3ffDeDuG9IvSUQkhyx+DF68DY6aChN+AEDMYjnVI083yEcAJ5vZq2Y218yOC6IoEZGcsOLv8PR3YOjJ+0wzNIwEiZCL26vNoRUzmwP0b2XVTcmf7wOcABwHPGZmh3orv6rMbBowDWDIkCHp1CwiknlNdzM8GC54CIpLmlaZGTk0stJ2kLv75FTrzOxqYFYyuF8zswRQDlS3sp/pwHSAysrKHDoEIiIt1O5quJuhxeDiz9/N0LCcGiNP96ZZTwFfBF40sxFACbAx3aJEREIV7woTboA+B0PfQz+3etzAcZSVlIVQWOvSDfIZwAwzWwLsAS5vbVhFRCRyjpqSctX3jv1eFgtpW1pB7u57gEsCqkVERDpBV3aKiEScglxEJOIU5CIiEacgFxGJOAW5iEjEKchFRCJOQS4iEnEWxvU7ZlYNrMh6w7mjHF0B2xYdo7bpGLVPPh2ng929ouWHoQR5oTOzKnevDLuOXKZj1DYdo/YphOOkoRURkYhTkIuIRJyCPBzTwy4gAnSM2qZj1D55f5w0Ri4iEnHqkYuIRJyCXEQk4hTkGWRmp5vZu2a23MxubGX9JDPbYmaLkq//CKPOsJjZDDPbkHwwSWvrzczuTh6/xWZ2TLZrDFs7jlFBn0MAZjbYzF4ws2VmttTM/qmVbfL6XEr3CUGSgpkVAfcApwKrgQVmNtvd326x6Xx3PzPrBeaGB4FfAQ+lWP9lYHjydTxwb/LPQvIg+z9GUNjnEEAdcL27v25mZcBCM3u+xf9reX0uqUeeOWOB5e7+YfJJSo8CZ4dcU05x93nApv1scjbwkDd4BehtZgOyU11uaMcxKnjuvtbdX0++3wYsAwa12CyvzyUFeeYMAlY1W17N508ugHFm9qaZ/dnMRmentMho7zEsdDqHksxsKPAPwKstVuX1uaShlcyxVj5rOdfzdRrunbDdzM4AnqLhn37SoD3HsNDpHEoysx7AH4F/dvetLVe38iN5cy6pR545q4HBzZYPAtY038Ddt7r79uT7Z4G4mZVnr8Sc1+YxLHQ6hxqYWZyGEJ/p7rNa2SSvzyUFeeYsAIab2SFmVgJcCMxuvoGZ9TczS74fS8N/j0+zXmnumg1clpxxcAKwxd3Xhl1ULtE51DAjBXgAWObuP0+xWV6fSxpayRB3rzOza4HngCJghrsvNbOrkuvvA74OXG1mdcBO4EIvoEttzewRYBJQbmargZuBODQdn2eBM4DlQA3wzXAqDU87jlFBn0NJ44FLgbfMbFHysx8BQ6AwziVdoi8iEnEaWhERiTgFuYhIxCnIRUQiTkEuIhJxCnIRkYhTkIuIRJyCXEQk4v4fxMyo4QVn2Y4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the model\n",
    "model = NewModel()\n",
    "model.load('../p2s_models/chair/img_encoder_0.545542_30000.pt', '../Models_Complete_Chairs/sketchRNN_decoder_0.874900_18000.pt')\n",
    "# img_test = '../Datasets/sketchy_cat/cat_p_test_resized/n02121620_26845.png'\n",
    "img_test = '../Datasets/sketchy_chair/chair_p_test_resized/n02738535_1198.png'\n",
    "img = mpimg.imread(img_test)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "z = model.p2s_encoder([img_test])\n",
    "model.conditional_generation(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
