{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\usera\\anaconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\usera\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\usera\\anaconda3\\lib\\site-packages (from torch) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# check the system we're on, gpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "np.load.__defaults__=(None, True, True, 'ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters():\n",
    "    def __init__(self):\n",
    "        self.data = '../Datasets/sketchrnn_chair.npz'\n",
    "        self.encoder_hidden_size = 64\n",
    "        self.decoder_hidden_size = 128\n",
    "        # latent vector\n",
    "        self.Nz = 32\n",
    "        \n",
    "        #return\n",
    "        self.M = 20\n",
    "        self.dropout = 0.9\n",
    "        self.batch_size = 100\n",
    "        self.eta_min = 0.01\n",
    "        self.R = 0.99995\n",
    "        self.KL_min = 0.2\n",
    "        self.wKL = 0.5\n",
    "        self.lr = 0.001\n",
    "        self.lr_decay = 0.9999\n",
    "        self.min_lr = 0.00001\n",
    "        self.grad_clip = 1.\n",
    "        self.temperature = 0.4\n",
    "        self.max_seq_length = 200\n",
    "\n",
    "hp = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        \n",
    "    def load_npz(self):\n",
    "        data = np.load(file=self.file, encoding='latin1', allow_pickle=True)\n",
    "        return data\n",
    "\n",
    "dataLoader = DataLoader(hp.data)\n",
    "data = dataLoader.load_npz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def padding(self, strokedata, max_len):\n",
    "        s = torch.from_numpy(strokedata)\n",
    "        s_len = s.shape[0]\n",
    "        result = torch.zeros((max_len, 5))\n",
    "        result[0:s_len, 0:2] = s[:, 0:2]\n",
    "        result[0:s_len, 3] = s[:, 2]\n",
    "        result[0:s_len, 2] = 1 - result[0:s_len, 3]    # 1 to 0, 0 to 1\n",
    "        if s_len < max_len:\n",
    "            result[(s_len - 1):, 4] = 1\n",
    "        return result\n",
    "        \n",
    "    def handle(self):\n",
    "        max_len = 0    # max length of a sketch - max number of stroke vectors in a sketch\n",
    "        for datatype in self.data:\n",
    "            for strokedata in self.data[datatype]:\n",
    "                if strokedata.shape[0] > max_len:\n",
    "                    max_len = strokedata.shape[0]\n",
    "        # lengths of data - the number of sketchs in data\n",
    "        train_len = self.data['train'].shape[0]\n",
    "        test_len = self.data['test'].shape[0]\n",
    "        valid_len = self.data['valid'].shape[0]\n",
    "        \n",
    "        data_train = torch.zeros((train_len, max_len, 5), dtype=float)\n",
    "        data_test = torch.zeros((test_len, max_len, 5), dtype=float)\n",
    "        data_valid = torch.zeros((valid_len, max_len, 5), dtype=float)\n",
    "        \n",
    "        i = j = k = 0\n",
    "        for datatype in self.data:\n",
    "            for strokedata in self.data[datatype]:\n",
    "                if datatype == 'train':\n",
    "                    data_train[i] = self.padding(strokedata, max_len)\n",
    "                    i += 1\n",
    "                if datatype == 'test':\n",
    "                    data_test[j] = self.padding(strokedata, max_len)\n",
    "                    j += 1\n",
    "                if datatype == 'valid':\n",
    "                    data_valid[k] = self.padding(strokedata, max_len)\n",
    "                    k += 1 \n",
    "\n",
    "        return data_train, data_test, data_valid\n",
    "    \n",
    "        \n",
    "datahandler = DataHandler(data)\n",
    "data_train, data_test, data_valid = datahandler.handle()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (2, 66, 64), got [2, 100, 64]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-43ac724233bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-43ac724233bd>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, batch_size, hidden_cell)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_hidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mhidden_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_cell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;31m# hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mhidden_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_backward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0m\u001b[0;32m    534\u001b[0m                                'Expected hidden[0] size {}, got {}')\n\u001b[0;32m    535\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    194\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 66, 64), got [2, 100, 64]"
     ]
    }
   ],
   "source": [
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         # bidirectional lstm:\n",
    "#         self.lstm = nn.LSTM(5, hp.encoder_hidden_size, bidirectional=True)\n",
    "#         # create mu and sigma from lstm's last output:\n",
    "#         self.fc_mu = nn.Linear(2*hp.encoder_hidden_size, hp.Nz)\n",
    "#         self.fc_sigma = nn.Linear(2*hp.encoder_hidden_size, hp.Nz)\n",
    "#         # active dropout:\n",
    "#         # self.train()\n",
    "\n",
    "#     def forward(self, inputs, batch_size, hidden_cell=None):\n",
    "#         if hidden_cell is None:\n",
    "#             # then must init with zeros\n",
    "#             if use_cuda:\n",
    "#                 hidden = torch.zeros(2, batch_size, hp.encoder_hidden_size).cuda()\n",
    "#                 cell = torch.zeros(2, batch_size, hp.encoder_hidden_size).cuda()\n",
    "#             else:\n",
    "#                 hidden = torch.zeros(2, batch_size, hp.encoder_hidden_size)\n",
    "#                 cell = torch.zeros(2, batch_size, hp.encoder_hidden_size)\n",
    "#             hidden_cell = (hidden, cell)\n",
    "#         _, (hidden,cell) = self.lstm(inputs.float(), hidden_cell)\n",
    "#         # hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\n",
    "#         hidden_forward, hidden_backward = torch.split(hidden,1,0)\n",
    "#         hidden_cat = torch.cat([hidden_forward.squeeze(0), hidden_backward.squeeze(0)],1)\n",
    "#         # mu and sigma:\n",
    "#         mu = self.fc_mu(hidden_cat)\n",
    "#         sigma_hat = self.fc_sigma(hidden_cat)\n",
    "#         sigma = torch.exp(sigma_hat/2.)\n",
    "#         # N ~ N(0,1)\n",
    "#         z_size = mu.size()\n",
    "                                   \n",
    "#         if use_cuda:\n",
    "#             N = torch.normal(torch.zeros(z_size),torch.ones(z_size)).cuda()\n",
    "#         else:\n",
    "#             N = torch.normal(torch.zeros(z_size),torch.ones(z_size))\n",
    "#         z = mu + sigma*N\n",
    "#         # mu and sigma_hat are needed for LKL loss\n",
    "#         return z, mu, sigma_hat\n",
    "    \n",
    "# encoder = Encoder()\n",
    "# encoder.train()\n",
    "# z, _, _ = encoder(data_train, hp.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[[[1, 2],\n",
      "          [3, 4]]],\n",
      "\n",
      "\n",
      "        [[[5, 6],\n",
      "          [7, 8]]]])\n",
      "(tensor([[[1, 2],\n",
      "         [3, 4]]]), tensor([[[5, 6],\n",
      "         [7, 8]]]))\n"
     ]
    }
   ],
   "source": [
    "# a = torch.rand((3,1,5))\n",
    "b = torch.tensor([[1,2], \n",
    "                  [3,4]])\n",
    "c = torch.tensor([[5,6],\n",
    "                  [7,8]])\n",
    "d = torch.stack([b.unsqueeze(0),c.unsqueeze(0)], 0)\n",
    "e = (b.unsqueeze(0).contiguous(),c.unsqueeze(0).contiguous())\n",
    "print(d.is_contiguous())\n",
    "print(d)\n",
    "print(e)\n",
    "# print(a.squeeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(hp.Nz + 5, hp.decoder_hidden_size)\n",
    "        self.fc_hc = nn.Linear(hp.Nz, 2*hp.decoder_hidden_size)\n",
    "        \n",
    "    def forward(self, inputs, z, hidden_cell=None):\n",
    "        if hidden_cell is None:       \n",
    "            hidden, cell = torch.split(F.tanh(self.fc_hc(z)), hp.decoder_hidden_size, 1)\n",
    "            hidden_cell = (hidden.unsqueeze(0), cell.unsqueeze(0))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forms part of the Model class\n",
    "\n",
    "\"\"\"\n",
    "This for after training, the paper says we can sample sketches for the model.\n",
    "During the sampling process we generate parameters for both GMM and categorical\n",
    "distributions at each time step, and sample an outcome S'i for that time step.\n",
    "\n",
    "GMM ->\n",
    "Categorical distributions -> calculated using outputs as logit values\n",
    "\n",
    "We continue to sample until p3, so the end of sketch, is 1 or the number of iterations\n",
    "has reached Nmax (length of longest sketch in training dataset). \n",
    "Sampling the output is not deterministic, it's a random sequence,\n",
    "conditioned on the input latent vector z. We can control the level of randomness we'd like\n",
    "our samples to have during the sampling process by using a temperature parameter.\n",
    "\n",
    "- state_q_hat tends to state_q_hat / temperature\n",
    "- prime_k tends to prime_k / temperature\n",
    "- sigma_squared_x tends to sigma_squared_temperature_x\n",
    "- sigma_squared_y tends to sigma_squared_temperature_y\n",
    "\n",
    "- the softmax parameters can be scaled, of the categorical distribution and also sigma\n",
    "parameters of the bivariate normal distribution by a temperature parameter temperature.\n",
    "To control the level of randomness in our samples.\n",
    "- temperature is usually between 0 and 1, so limit T -> 0, model becomes deterministic and\n",
    "samples will consist of the most likely point in the probability density function.\n",
    "\n",
    "- Unconditinal generation uses this temperature methodology to control randomness of the\n",
    "distribution\n",
    "\n",
    "Unconditional generation -> train model to generate sketches unconditionally where train\n",
    "decoder RNN module\n",
    "-> Initial hidden states and cell states of decoder RNN are initialized to zero, inputs xi\n",
    "of decoder RNN at each step is only Si-1 or Si-1', don't need to concatenate latent vectorZ\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def sample_sketch_state():\n",
    "\n",
    "def tweak_temperature(pi_pdf):\n",
    "    # sigma x = exp(sigma_hat), sigma_hat = log(Sigma x)\n",
    "    pi_pdf = np.log(pi_pdf)/hp.temperature\n",
    "    \n",
    "def sample_bivariate_normal():\n",
    "    \n",
    "def make_image():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
