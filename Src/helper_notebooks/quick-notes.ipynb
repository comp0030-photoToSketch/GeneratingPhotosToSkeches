{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([3, 120, 5])\n"
     ]
    }
   ],
   "source": [
    "T = 120\n",
    "batch_size = 3\n",
    "\n",
    "# dataset of batch_size drawing, length T \n",
    "S = torch.rand(batch_size, T, 5)\n",
    "print(\"input size:\", S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 64\n",
    "N_layers = 2\n",
    "lstm_layer = nn.LSTM(input_size=5, hidden_size=H, num_layers=N_layers, batch_first=True) # dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = 2 does the following:\n",
    "# lstm_A = nn.LSTM(input_size=5, hidden_size=H, num_layers=1, batch_first=True)\n",
    "# lstm_B = nn.LSTM(input_size=H, hidden_size=H, num_layers=1, batch_first=True)\n",
    "# lstm_B(lstm_A(S)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hidden, cell) = lstm_layer(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: torch.Size([3, 120, 64])\n"
     ]
    }
   ],
   "source": [
    "print(\"output size:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq embedding (final state): torch.Size([4, 3, 64])\n"
     ]
    }
   ],
   "source": [
    "print(\"seq embedding (final state):\", hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer_bi = nn.LSTM(input_size=5, hidden_size=H, batch_first=True, num_layers=N_layers, bidirectional=True)\n",
    "output, (hidden, cell) = lstm_layer_bi(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: torch.Size([3, 120, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"output size:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq embedding ('final' state): torch.Size([4, 3, 64])\n"
     ]
    }
   ],
   "source": [
    "print(\"seq embedding ('final' state):\", hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 64])\n",
      "torch.Size([3, 4, 64])\n",
      "torch.Size([3, 256])\n"
     ]
    }
   ],
   "source": [
    "# from h-> and h<- to h\n",
    "print(hidden.shape)\n",
    "h = hidden.transpose(0, 1)\n",
    "print(h.shape)\n",
    "h = h.reshape(batch_size, -1)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 2.]])\n",
      "tensor([[1., 1.],\n",
      "        [2., 2.],\n",
      "        [3., 2.]])\n",
      "tensor([[1., 1.],\n",
      "        [2., 2.],\n",
      "        [3., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# (note on what transpose does)\n",
    "A = torch.FloatTensor([[1, 2, 3],[1,2,2]])\n",
    "print(A)\n",
    "print(A.T)\n",
    "print(A.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=256, out_features=100, bias=True)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nz = 100\n",
    "mean_ = nn.Linear(2*N_layers*H, Nz)\n",
    "log_std_ = nn.Linear(2*N_layers*H, Nz)\n",
    "\n",
    "mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "\n",
    "# make sure to use rsample and not sample if you want to take gradients\n",
    "z = dist.Normal(loc=mean_(h), scale=log_std_(h).exp()).rsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([3, 119, 5]) torch.Size([3, 100])\n",
      "target torch.Size([3, 119, 5])\n"
     ]
    }
   ],
   "source": [
    "# make an LSTM\n",
    "# LSTM takes inputs (z, S_{t-1})\n",
    "\n",
    "print(\"input\", S[:,:-1].shape, z.shape) # need to concatenate these together at each timestep\n",
    "print(\"target\", S[:,1:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from s (at step t) and z: tensor([0.5226, 0.3804, 0.1333, 0.9342, 0.6991]) torch.Size([100])\n",
      "predict s (at t+1): tensor([0.2794, 0.8601, 0.7867, 0.3570, 0.9223])\n"
     ]
    }
   ],
   "source": [
    "# e.g.\n",
    "batch_index = 0\n",
    "t = 80\n",
    "print(\"from s (at step t) and z:\", S[batch_index,t], z[batch_index].shape)\n",
    "print(\"predict s (at t+1):\", S[batch_index,t+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 100]), torch.Size([3, 119, 100]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to \"expand\" z to be an input at every timestep\n",
    "z.shape, z.unsqueeze(1).expand([batch_size, T-1, z.shape[-1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 119, 105])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs will be something like\n",
    "\n",
    "torch.cat((S[:,:-1], z.unsqueeze(1).expand([batch_size, T-1, z.shape[-1]])), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 119, 5])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets will be like\n",
    "S[:, 1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 120, 5])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.]), tensor([0., 0., 1., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "s = [torch.Tensor([0,0,1,0,0])]\n",
    "#print(s)\n",
    "m = s*100 # 1,100\n",
    "print(m)\n",
    "[100 tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 5])\n",
      "torch.Size([1, 100, 5])\n"
     ]
    }
   ],
   "source": [
    "q = torch.stack(m)\n",
    "print(q.shape)\n",
    "#tensor array[array*100]\n",
    "r = q.unsqueeze(0)\n",
    "print(r.shape)\n",
    "[[[]]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
