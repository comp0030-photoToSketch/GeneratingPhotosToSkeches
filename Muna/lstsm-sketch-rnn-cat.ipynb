{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "np.load.__defaults__=(None, True, True, 'ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams():\n",
    "    def __init__(self):\n",
    "        self.data_location = '../Datasets/cat.npz'\n",
    "        self.enc_hidden_size = 256\n",
    "        self.dec_hidden_size = 512\n",
    "        self.Nz = 128\n",
    "        self.M = 20\n",
    "        self.dropout = 0.9\n",
    "        self.batch_size = 100\n",
    "        self.eta_min = 0.01\n",
    "        self.R = 0.99995\n",
    "        self.KL_min = 0.2\n",
    "        self.wKL = 0.5\n",
    "        self.lr = 0.001\n",
    "        self.lr_decay = 0.9999\n",
    "        self.min_lr = 0.00001\n",
    "        self.grad_clip = 1.\n",
    "        self.temperature = 0.4\n",
    "        self.max_seq_length = 200\n",
    "\n",
    "hp = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_size(data):\n",
    "    \"\"\"larger sequence length in the data set\"\"\"\n",
    "    sizes = [len(seq) for seq in data]\n",
    "    return max(sizes)\n",
    "\n",
    "def purify(strokes):\n",
    "    \"\"\"removes to small or too long sequences + removes large gaps\"\"\"\n",
    "    data = []\n",
    "    for seq in strokes:\n",
    "        if seq.shape[0] <= hp.max_seq_length and seq.shape[0] > 10:\n",
    "            seq = np.minimum(seq, 1000)\n",
    "            seq = np.maximum(seq, -1000)\n",
    "            seq = np.array(seq, dtype=np.float32)\n",
    "            data.append(seq)\n",
    "    return data\n",
    "\n",
    "def calculate_normalizing_scale_factor(strokes):\n",
    "    \"\"\"Calculate the normalizing factor explained in appendix of sketch-rnn.\"\"\"\n",
    "    data = []\n",
    "    for i in range(len(strokes)):\n",
    "        for j in range(len(strokes[i])):\n",
    "            data.append(strokes[i][j, 0])\n",
    "            data.append(strokes[i][j, 1])\n",
    "    data = np.array(data)\n",
    "    return np.std(data)\n",
    "\n",
    "def normalize(strokes):\n",
    "    \"\"\"Normalize entire dataset (delta_x, delta_y) by the scaling factor.\"\"\"\n",
    "    data = []\n",
    "    scale_factor = calculate_normalizing_scale_factor(strokes)\n",
    "    for seq in strokes:\n",
    "        seq[:, 0:2] /= scale_factor\n",
    "        data.append(seq)\n",
    "    return data\n",
    "\n",
    "dataset = np.load(hp.data_location, encoding='latin1')\n",
    "data = dataset['train']\n",
    "data = purify(data)\n",
    "data = normalize(data)\n",
    "Nmax = max_size(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(batch_size):\n",
    "    batch_idx = np.random.choice(len(data),batch_size)\n",
    "    batch_sequences = [data[idx] for idx in batch_idx]\n",
    "    strokes = []\n",
    "    lengths = []\n",
    "    indice = 0\n",
    "    for seq in batch_sequences:\n",
    "        len_seq = len(seq[:,0])\n",
    "        new_seq = np.zeros((Nmax,5)) # 66,5\n",
    "        new_seq[:len_seq,:2] = seq[:,:2]\n",
    "        new_seq[:len_seq-1,2] = 1-seq[:-1,2]\n",
    "        new_seq[:len_seq,3] = seq[:,2]\n",
    "        new_seq[(len_seq-1):,4] = 1\n",
    "        new_seq[len_seq-1,2:4] = 0\n",
    "        lengths.append(len(seq[:,0]))\n",
    "        strokes.append(new_seq)\n",
    "        indice += 1\n",
    "\n",
    "    if use_cuda:\n",
    "        batch = Variable(torch.from_numpy(np.stack(strokes,1)).cuda().float())\n",
    "    else:\n",
    "        batch = Variable(torch.from_numpy(np.stack(strokes,1)).float())\n",
    "    return batch, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(optimizer):\n",
    "    \"\"\"Decay learning rate by a factor of lr_decay\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['lr']>hp.min_lr:\n",
    "            param_group['lr'] *= hp.lr_decay\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # bidirectional lstm:\n",
    "        self.lstm = nn.LSTM(5, hp.enc_hidden_size, \\\n",
    "            dropout=hp.dropout, bidirectional=True)\n",
    "        # create mu and sigma from lstm's last output:\n",
    "        self.fc_mu = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
    "        self.fc_sigma = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
    "        # active dropout:\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, inputs, batch_size, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            # then must init with zeros\n",
    "            if use_cuda:\n",
    "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size).cuda()\n",
    "                cell = torch.zeros(2, batch_size, hp.enc_hidden_size).cuda()\n",
    "            else:\n",
    "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size)\n",
    "                cell = torch.zeros(2, batch_size, hp.enc_hidden_size)\n",
    "            hidden_cell = (hidden, cell)\n",
    "        _, (hidden,cell) = self.lstm(inputs.float(), hidden_cell)\n",
    "        # hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\n",
    "        hidden_forward, hidden_backward = torch.split(hidden,1,0)\n",
    "        hidden_cat = torch.cat([hidden_forward.squeeze(0), hidden_backward.squeeze(0)],1)\n",
    "        # mu and sigma:\n",
    "        mu = self.fc_mu(hidden_cat)\n",
    "        sigma_hat = self.fc_sigma(hidden_cat)\n",
    "        sigma = torch.exp(sigma_hat/2.)\n",
    "        # N ~ N(0,1)\n",
    "        z_size = mu.size()\n",
    "                                   \n",
    "        if use_cuda:\n",
    "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size)).cuda()\n",
    "        else:\n",
    "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size))\n",
    "        z = mu + sigma*N\n",
    "        # mu and sigma_hat are needed for LKL loss\n",
    "        return z, mu, sigma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # to init hidden and cell from z:\n",
    "        self.fc_hc = nn.Linear(hp.Nz, 2*hp.dec_hidden_size)\n",
    "        # unidirectional lstm:\n",
    "        self.lstm = nn.LSTM(hp.Nz+5, hp.dec_hidden_size, dropout=hp.dropout)\n",
    "        # create proba distribution parameters from hiddens:\n",
    "        self.fc_params = nn.Linear(hp.dec_hidden_size,6*hp.M+3)\n",
    "\n",
    "    def forward(self, inputs, z, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            # then we must init from z\n",
    "            hidden,cell = torch.split(F.tanh(self.fc_hc(z)),hp.dec_hidden_size,1)\n",
    "            hidden_cell = (hidden.unsqueeze(0).contiguous(), cell.unsqueeze(0).contiguous())\n",
    "        outputs,(hidden,cell) = self.lstm(inputs, hidden_cell)\n",
    "        # in training we feed the lstm with the whole input in one shot\n",
    "        # and use all outputs contained in 'outputs', while in generate\n",
    "        # mode we just feed with the last generated sample:\n",
    "        if self.training:\n",
    "            y = self.fc_params(outputs.view(-1, hp.dec_hidden_size))\n",
    "        else:\n",
    "            y = self.fc_params(hidden.view(-1, hp.dec_hidden_size))\n",
    "        # separate pen and mixture params:\n",
    "        params = torch.split(y,6,1)\n",
    "        params_mixture = torch.stack(params[:-1]) # trajectory\n",
    "        params_pen = params[-1] # pen up/down\n",
    "        # identify mixture params:\n",
    "        pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy = torch.split(params_mixture,1,2)\n",
    "        # preprocess params::\n",
    "        if self.training:\n",
    "            len_out = Nmax+1\n",
    "        else:\n",
    "            len_out = 1\n",
    "                                   \n",
    "        pi = F.softmax(pi.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_x = torch.exp(sigma_x.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_y = torch.exp(sigma_y.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        rho_xy = torch.tanh(rho_xy.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        mu_x = mu_x.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        mu_y = mu_y.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        q = F.softmax(params_pen).view(len_out,-1,3)\n",
    "        return pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy,q,hidden,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        if use_cuda:\n",
    "            self.encoder = EncoderRNN().cuda()\n",
    "            self.decoder = DecoderRNN().cuda()\n",
    "        else:\n",
    "            self.encoder = EncoderRNN()\n",
    "            self.decoder = DecoderRNN()\n",
    "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), hp.lr)\n",
    "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), hp.lr)\n",
    "        self.eta_step = hp.eta_min\n",
    "\n",
    "    def make_target(self, batch, lengths):\n",
    "        if use_cuda:\n",
    "            eos = torch.stack([torch.Tensor([0,0,0,0,1])]*batch.size()[1]).cuda().unsqueeze(0)\n",
    "        else:\n",
    "            eos = torch.stack([torch.Tensor([0,0,0,0,1])]*batch.size()[1]).unsqueeze(0)\n",
    "        batch = torch.cat([batch, eos], 0)\n",
    "        mask = torch.zeros(Nmax+1, batch.size()[1])\n",
    "        for indice,length in enumerate(lengths):\n",
    "            mask[:length,indice] = 1\n",
    "        if use_cuda:\n",
    "            mask = mask.cuda()\n",
    "        dx = torch.stack([batch.data[:,:,0]]*hp.M,2)\n",
    "        dy = torch.stack([batch.data[:,:,1]]*hp.M,2)\n",
    "        p1 = batch.data[:,:,2]\n",
    "        p2 = batch.data[:,:,3]\n",
    "        p3 = batch.data[:,:,4]\n",
    "        p = torch.stack([p1,p2,p3],2)\n",
    "        return mask,dx,dy,p\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        batch, lengths = make_batch(hp.batch_size)\n",
    "        # encode:\n",
    "        z, self.mu, self.sigma = self.encoder(batch, hp.batch_size)\n",
    "        # create start of sequence:\n",
    "        if use_cuda:\n",
    "            sos = torch.stack([torch.Tensor([0,0,1,0,0])]*hp.batch_size).cuda().unsqueeze(0)\n",
    "        else:\n",
    "            sos = torch.stack([torch.Tensor([0,0,1,0,0])]*hp.batch_size).unsqueeze(0)\n",
    "        # had sos at the begining of the batch:\n",
    "        batch_init = torch.cat([sos, batch],0)\n",
    "        # expend z to be ready to concatenate with inputs:\n",
    "        z_stack = torch.stack([z]*(Nmax+1))\n",
    "        # inputs is concatenation of z and batch_inputs\n",
    "        inputs = torch.cat([batch_init, z_stack],2)\n",
    "        # decode:\n",
    "        self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "            self.rho_xy, self.q, _, _ = self.decoder(inputs, z)\n",
    "        # prepare targets:\n",
    "        mask,dx,dy,p = self.make_target(batch, lengths)\n",
    "        # prepare optimizers:\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "        # update eta for LKL:\n",
    "        self.eta_step = 1-(1-hp.eta_min)*hp.R\n",
    "        # compute losses:\n",
    "        LKL = self.kullback_leibler_loss()\n",
    "        LR = self.reconstruction_loss(mask,dx,dy,p,epoch)\n",
    "        loss = LR + LKL\n",
    "        # gradient step\n",
    "        loss.backward()\n",
    "        # gradient cliping\n",
    "        nn.utils.clip_grad_norm(self.encoder.parameters(), hp.grad_clip)\n",
    "        nn.utils.clip_grad_norm(self.decoder.parameters(), hp.grad_clip)\n",
    "        # optim step\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "        # some print and save:\n",
    "        print(f\"The number of epochs is: {epoch}\")\n",
    "        if epoch%1==0:\n",
    "#             print('epoch',epoch,'loss',loss.data[0],'LR',LR.data[0],'LKL',LKL.data[0])\n",
    "            self.encoder_optimizer = lr_decay(self.encoder_optimizer)\n",
    "            self.decoder_optimizer = lr_decay(self.decoder_optimizer)\n",
    "        if epoch%200==0:\n",
    "            self.save(epoch)\n",
    "            self.conditional_generation(z)\n",
    "\n",
    "    def bivariate_normal_pdf(self, dx, dy):\n",
    "        z_x = ((dx-self.mu_x)/self.sigma_x)**2\n",
    "        z_y = ((dy-self.mu_y)/self.sigma_y)**2\n",
    "        z_xy = (dx-self.mu_x)*(dy-self.mu_y)/(self.sigma_x*self.sigma_y)\n",
    "        z = z_x + z_y -2*self.rho_xy*z_xy\n",
    "        exp = torch.exp(-z/(2*(1-self.rho_xy**2)))\n",
    "        norm = 2*np.pi*self.sigma_x*self.sigma_y*torch.sqrt(1-self.rho_xy**2)\n",
    "        return exp/norm\n",
    "\n",
    "    def reconstruction_loss(self, mask, dx, dy, p, epoch):\n",
    "        pdf = self.bivariate_normal_pdf(dx, dy)\n",
    "        LS = -torch.sum(mask*torch.log(1e-5+torch.sum(self.pi * pdf, 2)))\\\n",
    "            /float(Nmax*hp.batch_size)\n",
    "        LP = -torch.sum(p*torch.log(self.q))/float(Nmax*hp.batch_size)\n",
    "        return LS+LP\n",
    "\n",
    "    def kullback_leibler_loss(self):\n",
    "        LKL = -0.5*torch.sum(1+self.sigma-self.mu**2-torch.exp(self.sigma))\\\n",
    "            /float(hp.Nz*hp.batch_size)\n",
    "        if use_cuda:\n",
    "            KL_min = Variable(torch.Tensor([hp.KL_min]).cuda()).detach()\n",
    "        else:\n",
    "            KL_min = Variable(torch.Tensor([hp.KL_min])).detach()\n",
    "        return hp.wKL*self.eta_step * torch.max(LKL,KL_min)\n",
    "\n",
    "    def save(self, epoch):\n",
    "        random_number = np.random.rand()\n",
    "        enc_model_name = 'sketchRNN_encoder_%3f_%d.pt' % (random_number, epoch)\n",
    "        enc_path = F\"../Models/{enc_model_name}\"\n",
    "        torch.save(self.encoder.state_dict(), enc_path)\n",
    "        dec_model_name = 'sketchRNN_decoder_%3f_%d.pt' % (random_number, epoch)\n",
    "        dec_path = F\"../Models/{dec_model_name}\"\n",
    "        torch.save(self.decoder.state_dict(), dec_path)\n",
    "        \n",
    "#         torch.save(self.encoder.state_dict(), 'encoderRNN_sel_%3f_epoch_%d.pth' % (sel,epoch))\n",
    "#         torch.save(self.decoder.state_dict(), 'decoderRNN_sel_%3f_epoch_%d.pth' % (sel,epoch))\n",
    "\n",
    "    def load(self, encoder_name, decoder_name):\n",
    "        saved_encoder = torch.load(encoder_name)\n",
    "        saved_decoder = torch.load(decoder_name)\n",
    "        self.encoder.load_state_dict(saved_encoder)\n",
    "        self.decoder.load_state_dict(saved_decoder)\n",
    "\n",
    "    def conditional_generation(self, z):\n",
    "        batch,lengths = make_batch(1)\n",
    "        # should remove dropouts:\n",
    "        self.encoder.train(False)\n",
    "        self.decoder.train(False)\n",
    "        if use_cuda:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1).cuda())\n",
    "        else:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1))\n",
    "        s = sos\n",
    "        seq_x = []\n",
    "        seq_y = []\n",
    "        seq_z = []\n",
    "        hidden_cell = None\n",
    "        for i in range(Nmax):\n",
    "            inputs = torch.cat([s,z.unsqueeze(0)],2)\n",
    "            # decode:\n",
    "            self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "                self.rho_xy, self.q, hidden, cell = \\\n",
    "                    self.decoder(inputs, z, hidden_cell)\n",
    "            hidden_cell = (hidden, cell)\n",
    "            # sample from parameters:\n",
    "            s, dx, dy, pen_down, eos = self.sample_next_state()\n",
    "            #------\n",
    "            seq_x.append(dx)\n",
    "            seq_y.append(dy)\n",
    "            seq_z.append(pen_down)\n",
    "            if eos:\n",
    "                #print(i)\n",
    "                break\n",
    "        # visualize result:\n",
    "        x_sample = np.cumsum(seq_x, 0)\n",
    "        y_sample = np.cumsum(seq_y, 0)\n",
    "        z_sample = np.array(seq_z)\n",
    "        sequence = np.stack([x_sample,y_sample,z_sample]).T\n",
    "        make_image(sequence)\n",
    "\n",
    "    def sample_next_state(self):\n",
    "        def adjust_temp(pi_pdf):\n",
    "            pi_pdf = np.log(pi_pdf)/hp.temperature\n",
    "            pi_pdf -= pi_pdf.max()\n",
    "            pi_pdf = np.exp(pi_pdf)\n",
    "            pi_pdf /= pi_pdf.sum()\n",
    "            return pi_pdf\n",
    "\n",
    "        # get mixture indice:\n",
    "        pi = self.pi.data[0,0,:].cpu().numpy()\n",
    "        pi = adjust_temp(pi)\n",
    "        pi_idx = np.random.choice(hp.M, p=pi)\n",
    "        # get pen state:\n",
    "        q = self.q.data[0,0,:].cpu().numpy()\n",
    "        q = adjust_temp(q)\n",
    "        q_idx = np.random.choice(3, p=q)\n",
    "        # get mixture params:\n",
    "        mu_x = self.mu_x.data[0,0,pi_idx]\n",
    "        mu_y = self.mu_y.data[0,0,pi_idx]\n",
    "        sigma_x = self.sigma_x.data[0,0,pi_idx]\n",
    "        sigma_y = self.sigma_y.data[0,0,pi_idx]\n",
    "        rho_xy = self.rho_xy.data[0,0,pi_idx]\n",
    "        x,y = sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy,greedy=False)\n",
    "        next_state = torch.zeros(5)\n",
    "        next_state[0] = x\n",
    "        next_state[1] = y\n",
    "        next_state[q_idx+2] = 1\n",
    "        if use_cuda:\n",
    "            return Variable(next_state.cuda()).view(1,1,-1),x,y,q_idx==1,q_idx==2\n",
    "        else:\n",
    "            return Variable(next_state).view(1,1,-1),x,y,q_idx==1,q_idx==2\n",
    "\n",
    "def sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy, greedy=False):\n",
    "    # inputs must be floats\n",
    "    if greedy:\n",
    "        return mu_x,mu_y\n",
    "    mean = [mu_x, mu_y]\n",
    "    sigma_x *= np.sqrt(hp.temperature)\n",
    "    sigma_y *= np.sqrt(hp.temperature)\n",
    "    cov = [[sigma_x * sigma_x, rho_xy * sigma_x * sigma_y],\\\n",
    "        [rho_xy * sigma_x * sigma_y, sigma_y * sigma_y]]\n",
    "    x = np.random.multivariate_normal(mean, cov, 1)\n",
    "    return x[0][0], x[0][1]\n",
    "\n",
    "def make_image(sequence, name='_output_'):\n",
    "    \"\"\"plot drawing with separated strokes\"\"\"\n",
    "    strokes = np.split(sequence, np.where(sequence[:,2]>0)[0]+1)\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    for s in strokes:\n",
    "        plt.plot(s[:,0],-s[:,1])\n",
    "    print(\"Outputting sketch\")\n",
    "    plt.show()\n",
    "    #name = str(epoch)+name+'.jpg'\n",
    "    #plt.savefig(F\"./outputs_c/{name}\")\n",
    "    \n",
    "#     canvas = plt.get_current_fig_manager().canvas\n",
    "#     canvas.draw()\n",
    "#     pil_image = PIL.Image.frombytes('RGB', canvas.get_width_height(),\n",
    "#                  canvas.tostring_rgb())\n",
    "#     name = str(epoch)+name+'.jpg'\n",
    "#     pil_image.save(F\"./outputs_chair/{name}\",\"JPEG\")\n",
    "#     plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model()\n",
    "# for epoch in range(50001):\n",
    "#     model.train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use conditional generation function to test model\n",
    "\n",
    "# model = Model()\n",
    "# model.load('../Models/sketchRNN_encoder_0.497555_1600.pt','../Models/sketchRNN_decoder_0.497555_1600.pt')\n",
    "#model.conditional_generation(94803)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 - Passing random zs to the DecoderRNN to see the types of sketches produced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the sketchRNN (this is what we looked at on Friday). This learns an encoder, \"strokes-to-Z\", where Z is an embedding, and a decoder, \"Z-to-strokes\". This is the setup of the Ha & Eck paper. You can then take \"random\" values of Z to generate new random stroke sequences; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputting sketch\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "# Chose best model and sampled from gaussian to produce accurate cat images, outlier happens rarely\n",
    "model.load('../Models/sketchRNN_encoder_0.320616_7000.pt','../Models/sketchRNN_decoder_0.320616_7000.pt')\n",
    "\n",
    "# Sample z from gaussian distribution\n",
    "z = torch.randn(128)\n",
    "z = z.reshape(1, 128)\n",
    "\n",
    "# Reshape z for decode\n",
    "model.conditional_generation(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 - Interpolating between 2 stroke sequences to produce a new cat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do things like take two stroke sequences S1 and S2, run them through the encoder to find embeddings Z1 and Z2, and then interpolate between Z1 and Z2 before decoding in order to \"interpolate\" between stroke sequences. For the project writeup I think it would be nice to try to replicate some of the figures in the Ha & Eck paper using a sketchRNN that you train, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:238: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5910,  0.7002,  0.0000],\n",
      "        [-1.2304,  0.3465,  0.0000],\n",
      "        [-1.3983, -0.0449,  0.0000],\n",
      "        [-1.8213, -0.0727,  0.0000],\n",
      "        [-2.0998, -0.1742,  0.0000],\n",
      "        [-1.9824, -0.1370,  0.0000],\n",
      "        [-1.2739, -0.0835,  0.0000],\n",
      "        [ 0.9709, -0.0062,  0.0000],\n",
      "        [ 1.8481, -0.1400,  0.0000],\n",
      "        [ 2.1907, -0.5120,  0.0000],\n",
      "        [ 2.3678, -0.7409,  0.0000],\n",
      "        [ 2.4782, -0.8573,  0.0000],\n",
      "        [ 2.3806, -1.0655,  0.0000],\n",
      "        [ 2.1680, -1.3028,  0.0000],\n",
      "        [ 2.0781, -1.4564,  0.0000],\n",
      "        [ 1.8740, -1.5959,  1.0000],\n",
      "        [-0.3684, -0.8828,  0.0000],\n",
      "        [-0.3317, -0.9383,  1.0000],\n",
      "        [ 0.6168, -0.8876,  0.0000],\n",
      "        [ 0.6638, -0.7447,  0.0000],\n",
      "        [ 0.6334, -0.6278,  1.0000],\n",
      "        [ 0.5537, -1.0984,  0.0000],\n",
      "        [ 0.9479, -0.9268,  1.0000],\n",
      "        [-0.1870, -1.3997,  0.0000],\n",
      "        [ 0.0710, -1.9317,  1.0000],\n",
      "        [ 0.0821, -1.5416,  0.0000],\n",
      "        [ 0.2761, -1.7001,  1.0000],\n",
      "        [-0.0895, -1.5418,  0.0000],\n",
      "        [-0.1783, -1.5584,  1.0000],\n",
      "        [-0.0245, -1.9302,  0.0000],\n",
      "        [-0.0109, -1.9495,  1.0000],\n",
      "        [-0.2014, -1.7863,  0.0000],\n",
      "        [-0.1849, -1.8109,  1.0000],\n",
      "        [-0.3259, -2.1147,  0.0000],\n",
      "        [-0.2373, -1.8350,  1.0000],\n",
      "        [-0.4272, -2.2816,  0.0000],\n",
      "        [-0.4014, -1.8623,  1.0000],\n",
      "        [-0.5651, -2.1039,  0.0000],\n",
      "        [-0.5495, -2.1293,  1.0000],\n",
      "        [-0.6079, -2.1049,  0.0000],\n",
      "        [-0.6740, -1.7285,  0.0000]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (2, 41, 256), got [2, 1, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-183448cb346a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mstroke_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_3_to_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstroke_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#print(stroke_1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mz_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstroke_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#print(z_1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-f02dc4bb6272>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, batch_size, hidden_cell)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mhidden_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m# hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mhidden_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_backward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 534\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    535\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    536\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    194\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 41, 256), got [2, 1, 256]"
     ]
    }
   ],
   "source": [
    "def convert_3_to_5(v): # v shape (stroke_len, 3)\n",
    "    r = torch.zeros([v.shape[0], 5], dtype=float)\n",
    "    r[:,0:2] = v[:,0:2]\n",
    "    r[:,2] = v[:,2]\n",
    "    r[:,3] = 1 - r[:,2]\n",
    "    r[-1:4] = 1\n",
    "    r = r.unsqueeze(0)\n",
    "    return r\n",
    "\n",
    "model = Model()\n",
    "\n",
    "\n",
    "# Chose best model and sampled from gaussian to produce accurate cat images, outlier happens rarely\n",
    "model.load('../Models/sketchRNN_encoder_0.320616_7000.pt','../Models/sketchRNN_decoder_0.320616_7000.pt')\n",
    "\n",
    "# Get the first 2 cat sequences from data\n",
    "\n",
    "def getSingleSequence(alreadyChosen):\n",
    "    catSequences = make_batch(5)\n",
    "    random_idx = numpy.random.uniform(0,len(data),1)\n",
    "    while (random_idx == alreadyChosen):\n",
    "        random_idx = numpy.random.uniform(0,len(data),1)\n",
    "    \n",
    "    return strokes[random_idx]\n",
    "    \n",
    "\n",
    "# Interpolate z_1 and z_2\n",
    "def lerp(p0, p1, t):\n",
    "    \"\"\"Linear interpolation.\"\"\"\n",
    "    return (1.0 - t) * p0 + t * p1\n",
    "\n",
    "interpolated_z = lerp(z_1, z_2)\n",
    "\n",
    "model.conditional_generation(interpolated_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
