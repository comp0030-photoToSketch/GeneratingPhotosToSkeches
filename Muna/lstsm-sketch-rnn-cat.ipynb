{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "np.load.__defaults__=(None, True, True, 'ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams():\n",
    "    def __init__(self):\n",
    "        self.data_location = '../Datasets/cat.npz'\n",
    "        self.enc_hidden_size = 256\n",
    "        self.dec_hidden_size = 512\n",
    "        self.Nz = 128\n",
    "        self.M = 20\n",
    "        self.dropout = 0.9\n",
    "        self.batch_size = 100\n",
    "        self.eta_min = 0.01\n",
    "        self.R = 0.99995\n",
    "        self.KL_min = 0.2\n",
    "        self.wKL = 0.5\n",
    "        self.lr = 0.001\n",
    "        self.lr_decay = 0.9999\n",
    "        self.min_lr = 0.00001\n",
    "        self.grad_clip = 1.\n",
    "        self.temperature = 0.4\n",
    "        self.max_seq_length = 200\n",
    "\n",
    "hp = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_size(data):\n",
    "    \"\"\"larger sequence length in the data set\"\"\"\n",
    "    sizes = [len(seq) for seq in data]\n",
    "    return max(sizes)\n",
    "\n",
    "def purify(strokes):\n",
    "    \"\"\"removes to small or too long sequences + removes large gaps\"\"\"\n",
    "    data = []\n",
    "    for seq in strokes:\n",
    "        if seq.shape[0] <= hp.max_seq_length and seq.shape[0] > 10:\n",
    "            seq = np.minimum(seq, 1000)\n",
    "            seq = np.maximum(seq, -1000)\n",
    "            seq = np.array(seq, dtype=np.float32)\n",
    "            data.append(seq)\n",
    "    return data\n",
    "\n",
    "def calculate_normalizing_scale_factor(strokes):\n",
    "    \"\"\"Calculate the normalizing factor explained in appendix of sketch-rnn.\"\"\"\n",
    "    data = []\n",
    "    for i in range(len(strokes)):\n",
    "        for j in range(len(strokes[i])):\n",
    "            data.append(strokes[i][j, 0])\n",
    "            data.append(strokes[i][j, 1])\n",
    "    data = np.array(data)\n",
    "    return np.std(data)\n",
    "\n",
    "def normalize(strokes):\n",
    "    \"\"\"Normalize entire dataset (delta_x, delta_y) by the scaling factor.\"\"\"\n",
    "    data = []\n",
    "    scale_factor = calculate_normalizing_scale_factor(strokes)\n",
    "    for seq in strokes:\n",
    "        seq[:, 0:2] /= scale_factor\n",
    "        data.append(seq)\n",
    "    return data\n",
    "\n",
    "dataset = np.load(hp.data_location, encoding='latin1')\n",
    "data = dataset['train']\n",
    "data = purify(data)\n",
    "data = normalize(data)\n",
    "Nmax = max_size(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(batch_size):\n",
    "    batch_idx = np.random.choice(len(data),batch_size)\n",
    "    batch_sequences = [data[idx] for idx in batch_idx]\n",
    "    strokes = []\n",
    "    lengths = []\n",
    "    indice = 0\n",
    "    for seq in batch_sequences:\n",
    "        len_seq = len(seq[:,0])\n",
    "        new_seq = np.zeros((Nmax,5)) # 66,5\n",
    "        new_seq[:len_seq,:2] = seq[:,:2]\n",
    "        new_seq[:len_seq-1,2] = 1-seq[:-1,2]\n",
    "        new_seq[:len_seq,3] = seq[:,2]\n",
    "        new_seq[(len_seq-1):,4] = 1\n",
    "        new_seq[len_seq-1,2:4] = 0\n",
    "        lengths.append(len(seq[:,0]))\n",
    "        strokes.append(new_seq)\n",
    "        indice += 1\n",
    "\n",
    "    if use_cuda:\n",
    "        batch = Variable(torch.from_numpy(np.stack(strokes,1)).cuda().float())\n",
    "    else:\n",
    "        batch = Variable(torch.from_numpy(np.stack(strokes,1)).float())\n",
    "    return batch, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(optimizer):\n",
    "    \"\"\"Decay learning rate by a factor of lr_decay\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['lr']>hp.min_lr:\n",
    "            param_group['lr'] *= hp.lr_decay\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # bidirectional lstm:\n",
    "        self.lstm = nn.LSTM(5, hp.enc_hidden_size, \\\n",
    "            dropout=hp.dropout, bidirectional=True)\n",
    "        # create mu and sigma from lstm's last output:\n",
    "        self.fc_mu = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
    "        self.fc_sigma = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
    "        # active dropout:\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, inputs, batch_size, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            # then must init with zeros\n",
    "            if use_cuda:\n",
    "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size).cuda()\n",
    "                cell = torch.zeros(2, batch_size, hp.enc_hidden_size).cuda()\n",
    "            else:\n",
    "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size)\n",
    "                cell = torch.zeros(2, batch_size, hp.enc_hidden_size)\n",
    "            hidden_cell = (hidden, cell)\n",
    "        _, (hidden,cell) = self.lstm(inputs.float(), hidden_cell)\n",
    "        # hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\n",
    "        hidden_forward, hidden_backward = torch.split(hidden,1,0)\n",
    "        hidden_cat = torch.cat([hidden_forward.squeeze(0), hidden_backward.squeeze(0)],1)\n",
    "        # mu and sigma:\n",
    "        mu = self.fc_mu(hidden_cat)\n",
    "        sigma_hat = self.fc_sigma(hidden_cat)\n",
    "        sigma = torch.exp(sigma_hat/2.)\n",
    "        # N ~ N(0,1)\n",
    "        z_size = mu.size()\n",
    "                                   \n",
    "        if use_cuda:\n",
    "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size)).cuda()\n",
    "        else:\n",
    "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size))\n",
    "        z = mu + sigma*N\n",
    "        # mu and sigma_hat are needed for LKL loss\n",
    "        return z, mu, sigma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # to init hidden and cell from z:\n",
    "        self.fc_hc = nn.Linear(hp.Nz, 2*hp.dec_hidden_size)\n",
    "        # unidirectional lstm:\n",
    "        self.lstm = nn.LSTM(hp.Nz+5, hp.dec_hidden_size, dropout=hp.dropout)\n",
    "        # create proba distribution parameters from hiddens:\n",
    "        self.fc_params = nn.Linear(hp.dec_hidden_size,6*hp.M+3)\n",
    "\n",
    "    def forward(self, inputs, z, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            # then we must init from z\n",
    "            hidden,cell = torch.split(F.tanh(self.fc_hc(z)),hp.dec_hidden_size,1)\n",
    "            hidden_cell = (hidden.unsqueeze(0).contiguous(), cell.unsqueeze(0).contiguous())\n",
    "        outputs,(hidden,cell) = self.lstm(inputs, hidden_cell)\n",
    "        # in training we feed the lstm with the whole input in one shot\n",
    "        # and use all outputs contained in 'outputs', while in generate\n",
    "        # mode we just feed with the last generated sample:\n",
    "        if self.training:\n",
    "            y = self.fc_params(outputs.view(-1, hp.dec_hidden_size))\n",
    "        else:\n",
    "            y = self.fc_params(hidden.view(-1, hp.dec_hidden_size))\n",
    "        # separate pen and mixture params:\n",
    "        params = torch.split(y,6,1)\n",
    "        params_mixture = torch.stack(params[:-1]) # trajectory\n",
    "        params_pen = params[-1] # pen up/down\n",
    "        # identify mixture params:\n",
    "        pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy = torch.split(params_mixture,1,2)\n",
    "        # preprocess params::\n",
    "        if self.training:\n",
    "            len_out = Nmax+1\n",
    "        else:\n",
    "            len_out = 1\n",
    "                                   \n",
    "        pi = F.softmax(pi.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_x = torch.exp(sigma_x.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_y = torch.exp(sigma_y.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        rho_xy = torch.tanh(rho_xy.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        mu_x = mu_x.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        mu_y = mu_y.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        q = F.softmax(params_pen).view(len_out,-1,3)\n",
    "        return pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy,q,hidden,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        if use_cuda:\n",
    "            self.encoder = EncoderRNN().cuda()\n",
    "            self.decoder = DecoderRNN().cuda()\n",
    "        else:\n",
    "            self.encoder = EncoderRNN()\n",
    "            self.decoder = DecoderRNN()\n",
    "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), hp.lr)\n",
    "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), hp.lr)\n",
    "        self.eta_step = hp.eta_min\n",
    "\n",
    "    def make_target(self, batch, lengths):\n",
    "        if use_cuda:\n",
    "            eos = torch.stack([torch.Tensor([0,0,0,0,1])]*batch.size()[1]).cuda().unsqueeze(0)\n",
    "        else:\n",
    "            eos = torch.stack([torch.Tensor([0,0,0,0,1])]*batch.size()[1]).unsqueeze(0)\n",
    "        batch = torch.cat([batch, eos], 0)\n",
    "        mask = torch.zeros(Nmax+1, batch.size()[1])\n",
    "        for indice,length in enumerate(lengths):\n",
    "            mask[:length,indice] = 1\n",
    "        if use_cuda:\n",
    "            mask = mask.cuda()\n",
    "        dx = torch.stack([batch.data[:,:,0]]*hp.M,2)\n",
    "        dy = torch.stack([batch.data[:,:,1]]*hp.M,2)\n",
    "        p1 = batch.data[:,:,2]\n",
    "        p2 = batch.data[:,:,3]\n",
    "        p3 = batch.data[:,:,4]\n",
    "        p = torch.stack([p1,p2,p3],2)\n",
    "        return mask,dx,dy,p\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        batch, lengths = make_batch(hp.batch_size)\n",
    "        # encode:\n",
    "        z, self.mu, self.sigma = self.encoder(batch, hp.batch_size)\n",
    "        # create start of sequence:\n",
    "        if use_cuda:\n",
    "            sos = torch.stack([torch.Tensor([0,0,1,0,0])]*hp.batch_size).cuda().unsqueeze(0)\n",
    "        else:\n",
    "            sos = torch.stack([torch.Tensor([0,0,1,0,0])]*hp.batch_size).unsqueeze(0)\n",
    "        # had sos at the begining of the batch:\n",
    "        batch_init = torch.cat([sos, batch],0)\n",
    "        # expend z to be ready to concatenate with inputs:\n",
    "        z_stack = torch.stack([z]*(Nmax+1))\n",
    "        # inputs is concatenation of z and batch_inputs\n",
    "        inputs = torch.cat([batch_init, z_stack],2)\n",
    "        # decode:\n",
    "        self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "            self.rho_xy, self.q, _, _ = self.decoder(inputs, z)\n",
    "        # prepare targets:\n",
    "        mask,dx,dy,p = self.make_target(batch, lengths)\n",
    "        # prepare optimizers:\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "        # update eta for LKL:\n",
    "        self.eta_step = 1-(1-hp.eta_min)*hp.R\n",
    "        # compute losses:\n",
    "        LKL = self.kullback_leibler_loss()\n",
    "        LR = self.reconstruction_loss(mask,dx,dy,p,epoch)\n",
    "        loss = LR + LKL\n",
    "        # gradient step\n",
    "        loss.backward()\n",
    "        # gradient cliping\n",
    "        nn.utils.clip_grad_norm(self.encoder.parameters(), hp.grad_clip)\n",
    "        nn.utils.clip_grad_norm(self.decoder.parameters(), hp.grad_clip)\n",
    "        # optim step\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "        # some print and save:\n",
    "        print(f\"The number of epochs is: {epoch}\")\n",
    "        if epoch%1==0:\n",
    "#             print('epoch',epoch,'loss',loss.data[0],'LR',LR.data[0],'LKL',LKL.data[0])\n",
    "            self.encoder_optimizer = lr_decay(self.encoder_optimizer)\n",
    "            self.decoder_optimizer = lr_decay(self.decoder_optimizer)\n",
    "        if epoch%200==0:\n",
    "            self.save(epoch)\n",
    "            self.conditional_generation(z)\n",
    "\n",
    "    def bivariate_normal_pdf(self, dx, dy):\n",
    "        z_x = ((dx-self.mu_x)/self.sigma_x)**2\n",
    "        z_y = ((dy-self.mu_y)/self.sigma_y)**2\n",
    "        z_xy = (dx-self.mu_x)*(dy-self.mu_y)/(self.sigma_x*self.sigma_y)\n",
    "        z = z_x + z_y -2*self.rho_xy*z_xy\n",
    "        exp = torch.exp(-z/(2*(1-self.rho_xy**2)))\n",
    "        norm = 2*np.pi*self.sigma_x*self.sigma_y*torch.sqrt(1-self.rho_xy**2)\n",
    "        return exp/norm\n",
    "\n",
    "    def reconstruction_loss(self, mask, dx, dy, p, epoch):\n",
    "        pdf = self.bivariate_normal_pdf(dx, dy)\n",
    "        LS = -torch.sum(mask*torch.log(1e-5+torch.sum(self.pi * pdf, 2)))\\\n",
    "            /float(Nmax*hp.batch_size)\n",
    "        LP = -torch.sum(p*torch.log(self.q))/float(Nmax*hp.batch_size)\n",
    "        return LS+LP\n",
    "\n",
    "    def kullback_leibler_loss(self):\n",
    "        LKL = -0.5*torch.sum(1+self.sigma-self.mu**2-torch.exp(self.sigma))\\\n",
    "            /float(hp.Nz*hp.batch_size)\n",
    "        if use_cuda:\n",
    "            KL_min = Variable(torch.Tensor([hp.KL_min]).cuda()).detach()\n",
    "        else:\n",
    "            KL_min = Variable(torch.Tensor([hp.KL_min])).detach()\n",
    "        return hp.wKL*self.eta_step * torch.max(LKL,KL_min)\n",
    "\n",
    "    def save(self, epoch):\n",
    "        random_number = np.random.rand()\n",
    "        enc_model_name = 'sketchRNN_encoder_%3f_%d.pt' % (random_number, epoch)\n",
    "        enc_path = F\"../Models/{enc_model_name}\"\n",
    "        torch.save(self.encoder.state_dict(), enc_path)\n",
    "        dec_model_name = 'sketchRNN_decoder_%3f_%d.pt' % (random_number, epoch)\n",
    "        dec_path = F\"../Models/{dec_model_name}\"\n",
    "        torch.save(self.decoder.state_dict(), dec_path)\n",
    "        \n",
    "#         torch.save(self.encoder.state_dict(), 'encoderRNN_sel_%3f_epoch_%d.pth' % (sel,epoch))\n",
    "#         torch.save(self.decoder.state_dict(), 'decoderRNN_sel_%3f_epoch_%d.pth' % (sel,epoch))\n",
    "\n",
    "    def load(self, encoder_name, decoder_name):\n",
    "        saved_encoder = torch.load(encoder_name)\n",
    "        saved_decoder = torch.load(decoder_name)\n",
    "        self.encoder.load_state_dict(saved_encoder)\n",
    "        self.decoder.load_state_dict(saved_decoder)\n",
    "\n",
    "    def conditional_generation(self, z):\n",
    "        batch,lengths = make_batch(1)\n",
    "        # should remove dropouts:\n",
    "        self.encoder.train(False)\n",
    "        self.decoder.train(False)\n",
    "        if use_cuda:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1).cuda())\n",
    "        else:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1))\n",
    "        s = sos\n",
    "        seq_x = []\n",
    "        seq_y = []\n",
    "        seq_z = []\n",
    "        hidden_cell = None\n",
    "        for i in range(Nmax):\n",
    "            inputs = torch.cat([s,z.unsqueeze(0)],2)\n",
    "            # decode:\n",
    "            self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "                self.rho_xy, self.q, hidden, cell = \\\n",
    "                    self.decoder(inputs, z, hidden_cell)\n",
    "            hidden_cell = (hidden, cell)\n",
    "            # sample from parameters:\n",
    "            s, dx, dy, pen_down, eos = self.sample_next_state()\n",
    "            #------\n",
    "            seq_x.append(dx)\n",
    "            seq_y.append(dy)\n",
    "            seq_z.append(pen_down)\n",
    "            if eos:\n",
    "                #print(i)\n",
    "                break\n",
    "        # visualize result:\n",
    "        x_sample = np.cumsum(seq_x, 0)\n",
    "        y_sample = np.cumsum(seq_y, 0)\n",
    "        z_sample = np.array(seq_z)\n",
    "        sequence = np.stack([x_sample,y_sample,z_sample]).T\n",
    "        make_image(sequence)\n",
    "        \n",
    "    def getStrokeSequence(self, z):\n",
    "        self.encoder.train(False)\n",
    "        self.decoder.train(False)\n",
    "        if use_cuda:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1).cuda())\n",
    "        else:\n",
    "            sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1))\n",
    "        s = sos\n",
    "        seq_x = []\n",
    "        seq_y = []\n",
    "        seq_z = []\n",
    "        hidden_cell = None\n",
    "        for i in range(Nmax):\n",
    "            input = torch.cat([s,z.unsqueeze(0)],2)\n",
    "            # decode:\n",
    "            self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "                self.rho_xy, self.q, hidden, cell = \\\n",
    "                    self.decoder(input, z, hidden_cell)\n",
    "            hidden_cell = (hidden, cell)\n",
    "            # sample from parameters:\n",
    "            s, dx, dy, pen_down, eos = self.sample_next_state()\n",
    "            #-----\n",
    "            seq_x.append(dx)\n",
    "            seq_y.append(dy)\n",
    "            seq_z.append(pen_down)\n",
    "            if eos:\n",
    "                #print(i)\n",
    "                break\n",
    "        # visualize result:\n",
    "        x_sample = np.cumsum(seq_x, 0)\n",
    "        y_sample = np.cumsum(seq_y, 0)\n",
    "        z_sample = np.array(seq_z)\n",
    "        sequence = np.stack([x_sample,y_sample,z_sample]).T\n",
    "        torchSequence = torch.from_numpy(sequence)\n",
    "        return torchSequence\n",
    "\n",
    "    def sample_next_state(self):\n",
    "        def adjust_temp(pi_pdf):\n",
    "            pi_pdf = np.log(pi_pdf)/hp.temperature\n",
    "            pi_pdf -= pi_pdf.max()\n",
    "            pi_pdf = np.exp(pi_pdf)\n",
    "            pi_pdf /= pi_pdf.sum()\n",
    "            return pi_pdf\n",
    "\n",
    "        # get mixture indice:\n",
    "        pi = self.pi.data[0,0,:].cpu().numpy()\n",
    "        pi = adjust_temp(pi)\n",
    "        pi_idx = np.random.choice(hp.M, p=pi)\n",
    "        # get pen state:\n",
    "        q = self.q.data[0,0,:].cpu().numpy()\n",
    "        q = adjust_temp(q)\n",
    "        q_idx = np.random.choice(3, p=q)\n",
    "        # get mixture params:\n",
    "        mu_x = self.mu_x.data[0,0,pi_idx]\n",
    "        mu_y = self.mu_y.data[0,0,pi_idx]\n",
    "        sigma_x = self.sigma_x.data[0,0,pi_idx]\n",
    "        sigma_y = self.sigma_y.data[0,0,pi_idx]\n",
    "        rho_xy = self.rho_xy.data[0,0,pi_idx]\n",
    "        x,y = sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy,greedy=False)\n",
    "        next_state = torch.zeros(5)\n",
    "        next_state[0] = x\n",
    "        next_state[1] = y\n",
    "        next_state[q_idx+2] = 1\n",
    "        if use_cuda:\n",
    "            return Variable(next_state.cuda()).view(1,1,-1),x,y,q_idx==1,q_idx==2\n",
    "        else:\n",
    "            return Variable(next_state).view(1,1,-1),x,y,q_idx==1,q_idx==2\n",
    "\n",
    "def sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy, greedy=False):\n",
    "    # inputs must be floats\n",
    "    if greedy:\n",
    "        return mu_x,mu_y\n",
    "    mean = [mu_x, mu_y]\n",
    "    sigma_x *= np.sqrt(hp.temperature)\n",
    "    sigma_y *= np.sqrt(hp.temperature)\n",
    "    cov = [[sigma_x * sigma_x, rho_xy * sigma_x * sigma_y],\\\n",
    "        [rho_xy * sigma_x * sigma_y, sigma_y * sigma_y]]\n",
    "    x = np.random.multivariate_normal(mean, cov, 1)\n",
    "    return x[0][0], x[0][1]\n",
    "\n",
    "def make_image(sequence, name='_output_'):\n",
    "    \"\"\"plot drawing with separated strokes\"\"\"\n",
    "    strokes = np.split(sequence, np.where(sequence[:,2]>0)[0]+1)\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    for s in strokes:\n",
    "        plt.plot(s[:,0],-s[:,1])\n",
    "    print(\"Outputting sketch\")\n",
    "    plt.show()\n",
    "    #name = str(epoch)+name+'.jpg'\n",
    "    #plt.savefig(F\"./outputs_c/{name}\")\n",
    "    \n",
    "#     canvas = plt.get_current_fig_manager().canvas\n",
    "#     canvas.draw()\n",
    "#     pil_image = PIL.Image.frombytes('RGB', canvas.get_width_height(),\n",
    "#                  canvas.tostring_rgb())\n",
    "#     name = str(epoch)+name+'.jpg'\n",
    "#     pil_image.save(F\"./outputs_chair/{name}\",\"JPEG\")\n",
    "#     plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model()\n",
    "# for epoch in range(50001):\n",
    "#     model.train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use conditional generation function to test model\n",
    "\n",
    "# model = Model()\n",
    "# model.load('../Models/sketchRNN_encoder_0.497555_1600.pt','../Models/sketchRNN_decoder_0.497555_1600.pt')\n",
    "#model.conditional_generation(94803)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 - Passing random zs to the DecoderRNN to see the types of sketches produced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the sketchRNN (this is what we looked at on Friday). This learns an encoder, \"strokes-to-Z\", where Z is an embedding, and a decoder, \"Z-to-strokes\". This is the setup of the Ha & Eck paper. You can then take \"random\" values of Z to generate new random stroke sequences; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:241: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputting sketch\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "# Chose best model and sampled from gaussian to produce accurate cat images, outlier happens rarely\n",
    "model.load('../Models/sketchRNN_encoder_0.320616_7000.pt','../Models/sketchRNN_decoder_0.320616_7000.pt')\n",
    "\n",
    "# Sample z from gaussian distribution\n",
    "z = torch.randn(128)\n",
    "z = z.reshape(1, 128)\n",
    "\n",
    "# Reshape z for decode\n",
    "model.conditional_generation(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 - Interpolating between 2 stroke sequences to produce a new cat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do things like take two stroke sequences S1 and S2, run them through the encoder to find embeddings Z1 and Z2, and then interpolate between Z1 and Z2 before decoding in order to \"interpolate\" between stroke sequences. For the project writeup I think it would be nice to try to replicate some of the figures in the Ha & Eck paper using a sketchRNN that you train, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/muna/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:238: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([91, 3])\n",
      "torch.Size([1, 91, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (2, 91, 256), got [2, 1, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-b00b8f7d3b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mstroke_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_3_to_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstroke_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstroke_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mz_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstroke_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-f02dc4bb6272>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, batch_size, hidden_cell)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mhidden_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m# hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mhidden_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_backward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 534\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    535\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    536\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    194\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 91, 256), got [2, 1, 256]"
     ]
    }
   ],
   "source": [
    "def convert_3_to_5(v): # v shape (stroke_len, 3)\n",
    "    r = torch.zeros([v.shape[0], 5], dtype=float)\n",
    "    r[:,0:2] = v[:,0:2]\n",
    "    r[:,2] = v[:,2]\n",
    "    r[:,3] = 1 - r[:,2]\n",
    "    r[-1:4] = 1\n",
    "    r = r.unsqueeze(0)\n",
    "    return r\n",
    "\n",
    "model = Model()\n",
    "\n",
    "\n",
    "# Chose best model and sampled from gaussian to produce accurate cat images, outlier happens rarely\n",
    "model.load('../Models/sketchRNN_encoder_0.320616_7000.pt','../Models/sketchRNN_decoder_0.320616_7000.pt')\n",
    "\n",
    "# Sample z from gaussian distribution\n",
    "z_1 = torch.randn(128)\n",
    "z_1 = z.reshape(1, 128)\n",
    "\n",
    "z_2 = torch.randn(128)\n",
    "z_2 = z.reshape(1, 128)\n",
    "\n",
    "# Get output image from our saved model\n",
    "stroke_1 = model.getStrokeSequence(z_1)\n",
    "stroke_2 = model.getStrokeSequence(z_2)\n",
    "\n",
    "print(stroke_1.shape)\n",
    "stroke_1 = convert_3_to_5(stroke_1)\n",
    "print(stroke_1.shape)\n",
    "z_1, _, _ = model.encoder(stroke_1, 1)\n",
    "print(z_1.shape)\n",
    "\n",
    "stroke_2 = convert_3_to_5(stroke_2)\n",
    "z_2, _, _ = model.encoder(stroke_2, 1)\n",
    "\n",
    "\n",
    "# Interpolate z_1 and z_2\n",
    "def lerp(p0, p1, t):\n",
    "    \"\"\"Linear interpolation.\"\"\"\n",
    "    return (1.0 - t) * p0 + t * p1\n",
    "\n",
    "interpolated_z = lerp(z_1, z_2)\n",
    "\n",
    "model.conditional_generation(interpolated_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
