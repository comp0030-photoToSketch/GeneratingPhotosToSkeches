{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports needed\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "import cv2\n",
    "import os\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data needed:\n",
    "ImageEncoder Input: [PNG Image -> Greyscale], shape = [28x28]\n",
    "             Output: Latent vector z, shape = [1,128]\n",
    "\n",
    "SketchDecoderRNN Input: Latent z\n",
    "                 Output: Stroke sequence\n",
    "                 \n",
    "Training:\n",
    "    -> Compare generated z and EncoderRNN[Corresponding seq to PNG Image]\n",
    "    -> 3 losses\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# For predictive model encoder optimization\n",
    "# input Photo path, ordered to match\n",
    "train_photo_image_path = \"../Datasets/cat/train\"\n",
    "test_photo_image_path = \"../Datasets/cat/test\"\n",
    "valid_photo_image_path = \"../Datasets/cat/valid\"\n",
    "\n",
    "# paired input, sequence arrays\n",
    "seq_data = \"../Datasets/cat.npz\"\n",
    "\n",
    "# set epochs, similar to the training loop needed for sketchRNN\n",
    "epochs = 10000\n",
    "image_size = 28 # 28 x 28 size\n",
    "\n",
    "Nmax = 200 #largest stroke length\n",
    "eta_min = 0 #lkl loss\n",
    "R = 0 #lkl loss\n",
    "\n",
    "# load the dataset, convert images and vectors to tensors\n",
    "image_sequence_dataset = LoadData(X, input_sequence_path)\n",
    "\n",
    "# transform dataset to torch representation\n",
    "torch_train_ImgSeq = DataLoader(image_sequence_dataset, shuffle=True, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class deals with dataset loading\n",
    "class Cat(Dataset):\n",
    "    # initialise paths to the X = image, y = paired strokes\n",
    "    # function to give the length of dataset\n",
    "    # transform the images to tensors \n",
    "    # transform the stroke data to tensors\n",
    "    # resize the images so they're the correct size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder that takes in the latent vector z, and the stroke data\n",
    "\n",
    "# this class takes in the image and outputs a vector z\n",
    "class ImageEncoder(Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        input_shape = image_size**2*2 # 0 or 1, black and white\n",
    "        self.enc_h1 = nn.Linear(in_features=input_shape, out_features=128)\n",
    "        self.enc_out = nn.Linear(in_features=128, out_features=bottleneck_size)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        h1_ac = torch.relu(self.enc_h1(image))\n",
    "        h2_out = self.enc_out(h1_ac)\n",
    "        z = torch.sigmoid(h2_out)\n",
    "        return z\n",
    "        \n",
    "# this class takes in vector z and outputs a sequence for the sketch\n",
    "class StrokeDecoder(Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        # define sketchRNN decoder architecture\n",
    "        self.fc_hc = nn.Linear(hp.Nz, 2*hp.dec_hidden_size)\n",
    "        self.lstm = nn.LSTM(hp.Nz+5, hp.dec_hidden_size, dropout=hp.dropout)\n",
    "        self.fc_params = nn.Linear(hp.dec_hidden_size,6*hp.M+3)\n",
    "        \n",
    "    def forward(self, x2_inputs, z_vector):\n",
    "        # pass z_vector to decoder layers and produce stroke data\n",
    "        # similar to the conditional generation model\n",
    "        if self.training:\n",
    "            y = self.fc_params(outputs.view(-1, hp.dec_hidden_size))\n",
    "        else:\n",
    "            y = self.fc_params(hidden.view(-1, hp.dec_hidden_size))\n",
    "        # separate pen and mixture params:\n",
    "        params = torch.split(y,6,1)\n",
    "        params_mixture = torch.stack(params[:-1]) # trajectory\n",
    "        params_pen = params[-1] # pen up/down\n",
    "        # identify mixture params:\n",
    "        pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy = torch.split(params_mixture,1,2)\n",
    "        # preprocess params::\n",
    "        if self.training:\n",
    "            len_out = Nmax+1\n",
    "        else:\n",
    "            len_out = 1\n",
    "                                   \n",
    "        pi = F.softmax(pi.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_x = torch.exp(sigma_x.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_y = torch.exp(sigma_y.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        rho_xy = torch.tanh(rho_xy.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        mu_x = mu_x.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        mu_y = mu_y.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        q = F.softmax(params_pen).view(len_out,-1,3)\n",
    "        return pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy,q,hidden,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhotoToSketch():\n",
    "    def __init__(self):\n",
    "        if use_cuda:\n",
    "            self.encoder = ImageEncoder().cuda()\n",
    "            self.decoder = StrokeDecoder().cuda()\n",
    "        else:\n",
    "            self.encoder = ImageEncoder()\n",
    "            self.decoder = StrokeDecoder()\n",
    "        self.encoder_optimizer = optim.Adam([{'params': encoder.parameters(), 'lr': 1e-3}, {'params': decoder.parameters(), 'lr': 1e-3}], lr=1e-3)\n",
    "        self.decoder_optimizer = optim.Adam([{'params': encoder.parameters(), 'lr': 1e-3}, {'params': decoder.parameters(), 'lr': 1e-3}], lr=1e-3)\n",
    "        self.eta_step = eta_min\n",
    "\n",
    "    def train(self, epoch):\n",
    "        for i,data in enumerate(torch_train_ImgSeq):\n",
    "            # Training loop to update weights for Photo To Sketch model\n",
    "            self.encoder.train()\n",
    "            self.decoder.train()\n",
    "            X2, lengths = extract_lengths()\n",
    "\n",
    "            z = self.encoder(torch_train_ImgSeq)\n",
    "            if use_cuda:\n",
    "                sos = torch.stack([torch.Tensor([0,0,1,0,0])]*num_of_images).cuda().unsqueeze(0)\n",
    "            else:\n",
    "                sos = torch.stack([torch.Tensor([0,0,1,0,0])]*num_of_images).unsqueeze(0)\n",
    "            init = torch.cat([sos, X2], 0)\n",
    "            z_stack = torch.stack([z]*(Nmax+1))\n",
    "            inputs = torch.cat([init, z_stack],2)\n",
    "            self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "                self.rho_xy, self.q, _, _ = self.decoder(inputs, z)\n",
    "            mask,dx,dy,p = self.make_target(X2, lengths)\n",
    "\n",
    "            self.encoder_optimizer.zero_grad()\n",
    "            self.decoder_optimizer.zero_grad()\n",
    "\n",
    "            self.eta_step = 1-(1-eta_min)*R\n",
    "\n",
    "            # compute all losses: EncoderLoss, LKL, reconstructionLoss\n",
    "            EL = loss_function(z, target_z) \n",
    "            KLL = self.kullback_leibler_loss()\n",
    "            RL = self.reconstruction_loss(mask,dx,dy,p,epoch)\n",
    "            loss = RL + KLL + EL # may need to include weight here for EL\n",
    "            \n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm(self.encoder.parameters(), hp.grad_clip)\n",
    "            nn.utils.clip_grad_norm(self.decoder.parameters(), hp.grad_clip)\n",
    "            self.encoder_optimizer.step()\n",
    "            self.decoder_optimizer.step()\n",
    "            if epoch%1==0:\n",
    "    #             print('epoch',epoch,'loss',loss.data[0],'LR',LR.data[0],'LKL',LKL.data[0])\n",
    "                self.encoder_optimizer = lr_decay(self.encoder_optimizer)\n",
    "                self.decoder_optimizer = lr_decay(self.decoder_optimizer)\n",
    "            if epoch%200==0:\n",
    "                self.save(epoch)\n",
    "                self.conditional_generation(epoch)\n",
    "\n",
    "#         train_loss = []\n",
    "#         for epoch in range(epochs):\n",
    "#             running_loss = 0.0\n",
    "#             for i,data in enumerate(torch_train_ImgSeq):\n",
    "#                 photo = data[0]\n",
    "#                 target_z = data[1]\n",
    "#                 optimizer.zero_grad()\n",
    "#                 latent_out = encode(photo)\n",
    "#                 # calculate the loss dependent on the output z and target z\n",
    "#                 loss = loss_function(latent_out, target_z)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 running_loss += loss.item()\n",
    "#                 outputs = decode(latent_out) # only do the decoder part when the optimal encoder has been found\n",
    "\n",
    "#             loss = running_loss / len(torch_train_ImgSeq)\n",
    "#             train_loss.append(loss)\n",
    "#             print(f'Epoch {ep+1} of {epochs}, Train Loss: {loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy, greedy=False):\n",
    "    # inputs must be floats\n",
    "    if greedy:\n",
    "        return mu_x,mu_y\n",
    "    mean = [mu_x, mu_y]\n",
    "    sigma_x *= np.sqrt(hp.temperature)\n",
    "    sigma_y *= np.sqrt(hp.temperature)\n",
    "    cov = [[sigma_x * sigma_x, rho_xy * sigma_x * sigma_y],\\\n",
    "        [rho_xy * sigma_x * sigma_y, sigma_y * sigma_y]]\n",
    "    x = np.random.multivariate_normal(mean, cov, 1)\n",
    "    return x[0][0], x[0][1]\n",
    "\n",
    "# loss function to compare produced_z with given z\n",
    "def loss_function(predicted_z, target_z):\n",
    "    # uses mean square loss\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion(predicted_z, target_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "\n",
    "def test(photos):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    idx = 0\n",
    "    for x, y in photos:\n",
    "        show_image(x, idx+1, \"Before sketching:\")\n",
    "        make_image(y, idx+2, \"Target sketch:\")\n",
    "        out = encode(x)\n",
    "        out = decode(out)\n",
    "        make_image(out, idx+3, \"Predicted sketch:\")\n",
    "        idx += 3\n",
    "        \n",
    "def show_image(image, idx, label):\n",
    "    img = image.squeeze().permute(1, 2, 0).detach().numpy()\n",
    "    plt.subplot(3, 3, idx)\n",
    "    plt.title(label)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "def make_image(sequence, idx, label):\n",
    "    \n",
    "    img_path = f\"{hp.test_photo_image_path}{i}.png\"\n",
    "    img = mpimg.imread(img_path)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "#edi this function\n",
    "# def make_image(sequence, epoch, name='_output_'):\n",
    "#     \"\"\"plot drawing with separated strokes\"\"\"\n",
    "#     strokes = np.split(sequence, np.where(sequence[:,2]>0)[0]+1)\n",
    "#     fig = plt.figure()\n",
    "#     ax1 = fig.add_subplot(111)\n",
    "#     for s in strokes:\n",
    "#         plt.plot(s[:,0],-s[:,1])\n",
    "#     print(\"Outputting sketch\")\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit48daa9eb24a74ae49d938de048518b69"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
